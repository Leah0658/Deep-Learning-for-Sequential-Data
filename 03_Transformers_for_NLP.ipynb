{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAVPM0BnTdd4"
   },
   "source": [
    "## Section 2: Deep Learning for Sequential Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FAgUSME4TsCP"
   },
   "source": [
    "### <font color=\"#0b486b\">Set random seeds</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5DaYHAIv4poj"
   },
   "source": [
    "We need to install the package datasets for creating BERT datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5082,
     "status": "ok",
     "timestamp": 1730099880620,
     "user": {
      "displayName": "Leah",
      "userId": "09729964029713612593"
     },
     "user_tz": -660
    },
    "id": "o7ik_46Y4vDo",
    "outputId": "9ed5f310-7795-4f25-c3c9-e52e0984be93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.16.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
      "Downloading datasets-3.0.2-py3-none-any.whl (472 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.7/472.7 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n",
      "Successfully installed datasets-3.0.2 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g6b0SM034sf2"
   },
   "source": [
    "We start with importing PyTorch and NumPy and setting random seeds for PyTorch and NumPy. You can use any seeds you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 1819,
     "status": "ok",
     "timestamp": 1730099882437,
     "user": {
      "displayName": "Leah",
      "userId": "09729964029713612593"
     },
     "user_tz": -660
    },
    "id": "O7XWUry0JXCc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import BertTokenizer\n",
    "import os\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1730099882438,
     "user": {
      "displayName": "Leah",
      "userId": "09729964029713612593"
     },
     "user_tz": -660
    },
    "id": "6ZoWqunmUY7L"
   },
   "outputs": [],
   "source": [
    "def seed_all(seed=1029):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_all(seed=1234)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6VU1jS6SUl8q"
   },
   "source": [
    "## <font color=\"#0b486b\">Download and preprocess the data</font>\n",
    "\n",
    "<div style=\"text-align: right\"><font color=\"red; font-weight:bold\"><span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQEzWmZjUulL"
   },
   "source": [
    "The dataset we use for this assignment is a question classification dataset for which the training set consists of $5,500$ questions belonging to 6 coarse question categories including:\n",
    "- abbreviation (ABBR),\n",
    "- entity (ENTY),\n",
    "- description (DESC),\n",
    "- human (HUM),\n",
    "- location (LOC) and\n",
    "- numeric (NUM).\n",
    "\n",
    "In this assignment, we will utilize a subset of this dataset, containing $2,000$ questions for training and validation. We will use 80% of those 2000 questions for trainning and the rest for validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zOd49RTpUxxj"
   },
   "source": [
    "Preprocessing data is a crucial initial step in any machine learning or deep learning project. The *TextDataManager* class simplifies the process by providing functionalities to download and preprocess data specifically designed for the subsequent questions in this assignment. It is highly recommended to gain a comprehensive understanding of the class's functionality by **carefully reading** the content provided in the *TextDataManager* class before proceeding to answer the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1730099882438,
     "user": {
      "displayName": "Leah",
      "userId": "09729964029713612593"
     },
     "user_tz": -660
    },
    "id": "_C2fuJNzUhha"
   },
   "outputs": [],
   "source": [
    "class DataManager:\n",
    "    \"\"\"\n",
    "    This class manages and preprocesses a simple text dataset for a sentence classification task.\n",
    "\n",
    "    Attributes:\n",
    "        verbose (bool): Controls verbosity for printing information during data processing.\n",
    "        max_sentence_len (int): The maximum length of a sentence in the dataset.\n",
    "        str_questions (list): A list to store the string representations of the questions in the dataset.\n",
    "        str_labels (list): A list to store the string representations of the labels in the dataset.\n",
    "        numeral_labels (list): A list to store the numerical representations of the labels in the dataset.\n",
    "        maxlen (int): Maximum length for padding sequences. Sequences longer than this length will be truncated,\n",
    "            and sequences shorter than this length will be padded with zeros. Defaults to 50.\n",
    "        numeral_data (list): A list to store the numerical representations of the questions in the dataset.\n",
    "        random_state (int): Seed value for random number generation to ensure reproducibility.\n",
    "            Set this value to a specific integer to reproduce the same random sequence every time. Defaults to 6789.\n",
    "        random (np.random.RandomState): Random number generator object initialized with the given random_state.\n",
    "            It is used for various random operations in the class.\n",
    "\n",
    "    Methods:\n",
    "        maybe_download(dir_name, file_name, url, verbose=True):\n",
    "            Downloads a file from a given URL if it does not exist in the specified directory.\n",
    "            The directory and file are created if they do not exist.\n",
    "\n",
    "        read_data(dir_name, file_names):\n",
    "            Reads data from files in a directory, preprocesses it, and computes the maximum sentence length.\n",
    "            Each file is expected to contain rows in the format \"<label>:<question>\".\n",
    "            The labels and questions are stored as string representations.\n",
    "\n",
    "        manipulate_data():\n",
    "            Performs data manipulation by tokenizing, numericalizing, and padding the text data.\n",
    "            The questions are tokenized and converted into numerical sequences using a tokenizer.\n",
    "            The sequences are padded or truncated to the maximum sequence length.\n",
    "\n",
    "        train_valid_test_split(train_ratio=0.9):\n",
    "            Splits the data into training, validation, and test sets based on a given ratio.\n",
    "            The data is randomly shuffled, and the specified ratio is used to determine the size of the training set.\n",
    "            The string questions, numerical data, and numerical labels are split accordingly.\n",
    "            TensorFlow `Dataset` objects are created for the training and validation sets.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, verbose=True, random_state=6789):\n",
    "        self.verbose = verbose\n",
    "        self.max_sentence_len = 0\n",
    "        self.str_questions = list()\n",
    "        self.str_labels = list()\n",
    "        self.numeral_labels = list()\n",
    "        self.numeral_data = list()\n",
    "        self.random_state = random_state\n",
    "        self.random = np.random.RandomState(random_state)\n",
    "\n",
    "    @staticmethod\n",
    "    def maybe_download(dir_name, file_name, url, verbose=True):\n",
    "        if not os.path.exists(dir_name):\n",
    "            os.mkdir(dir_name)\n",
    "        if not os.path.exists(os.path.join(dir_name, file_name)):\n",
    "            urlretrieve(url + file_name, os.path.join(dir_name, file_name))\n",
    "        if verbose:\n",
    "            print(\"Downloaded successfully {}\".format(file_name))\n",
    "\n",
    "    def read_data(self, dir_name, file_names):\n",
    "        self.str_questions = list()\n",
    "        self.str_labels = list()\n",
    "        for file_name in file_names:\n",
    "            file_path= os.path.join(dir_name, file_name)\n",
    "            with open(file_path, \"r\", encoding=\"latin-1\") as f:\n",
    "                for row in f:\n",
    "                    row_str = row.split(\":\")\n",
    "                    label, question = row_str[0], row_str[1]\n",
    "                    question = question.lower()\n",
    "                    self.str_labels.append(label)\n",
    "                    self.str_questions.append(question[0:-1])\n",
    "                    if self.max_sentence_len < len(self.str_questions[-1]):\n",
    "                        self.max_sentence_len = len(self.str_questions[-1])\n",
    "\n",
    "        # turns labels into numbers\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(self.str_labels)\n",
    "        self.numeral_labels = np.array(le.transform(self.str_labels))\n",
    "        self.str_classes = le.classes_\n",
    "        self.num_classes = len(self.str_classes)\n",
    "        if self.verbose:\n",
    "            print(\"\\nSample questions and corresponding labels... \\n\")\n",
    "            print(self.str_questions[0:5])\n",
    "            print(self.str_labels[0:5])\n",
    "\n",
    "    def manipulate_data(self):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        vocab = self.tokenizer.get_vocab()\n",
    "        self.word2idx = {w: i for i, w in enumerate(vocab)}\n",
    "        self.idx2word = {i:w for w,i in self.word2idx.items()}\n",
    "        self.vocab_size = len(self.word2idx)\n",
    "\n",
    "        token_ids = []\n",
    "        num_seqs = []\n",
    "        for text in self.str_questions:  # iterate over the list of text\n",
    "          text_seqs = self.tokenizer.tokenize(str(text))  # tokenize each text individually\n",
    "          # Convert tokens to IDs\n",
    "          token_ids = self.tokenizer.convert_tokens_to_ids(text_seqs)\n",
    "          # Convert token IDs to a tensor of indices using your word2idx mapping\n",
    "          seq_tensor = torch.LongTensor(token_ids)\n",
    "          num_seqs.append(seq_tensor)  # append the tensor for each sequence\n",
    "\n",
    "        # Pad the sequences and create a tensor\n",
    "        if num_seqs:\n",
    "          self.numeral_data = pad_sequence(num_seqs, batch_first=True)  # Pads to max length of the sequences\n",
    "          self.num_sentences, self.max_seq_len = self.numeral_data.shape\n",
    "\n",
    "    def train_valid_test_split(self, train_ratio=0.8, test_ratio = 0.1):\n",
    "        train_size = int(self.num_sentences*train_ratio) +1\n",
    "        test_size = int(self.num_sentences*test_ratio) +1\n",
    "        valid_size = self.num_sentences - (train_size + test_size)\n",
    "        data_indices = list(range(self.num_sentences))\n",
    "        random.shuffle(data_indices)\n",
    "        self.train_str_questions = [self.str_questions[i] for i in data_indices[:train_size]]\n",
    "        self.train_numeral_labels = self.numeral_labels[data_indices[:train_size]]\n",
    "        train_set_data = self.numeral_data[data_indices[:train_size]]\n",
    "        train_set_labels = self.numeral_labels[data_indices[:train_size]]\n",
    "        train_set_labels = torch.from_numpy(train_set_labels)\n",
    "        train_set = torch.utils.data.TensorDataset(train_set_data, train_set_labels)\n",
    "        self.test_str_questions = [self.str_questions[i] for i in data_indices[-test_size:]]\n",
    "        self.test_numeral_labels = self.numeral_labels[data_indices[-test_size:]]\n",
    "        test_set_data = self.numeral_data[data_indices[-test_size:]]\n",
    "        test_set_labels = self.numeral_labels[data_indices[-test_size:]]\n",
    "        test_set_labels = torch.from_numpy(test_set_labels)\n",
    "        test_set = torch.utils.data.TensorDataset(test_set_data, test_set_labels)\n",
    "        self.valid_str_questions = [self.str_questions[i] for i in data_indices[train_size:-test_size]]\n",
    "        self.valid_numeral_labels = self.numeral_labels[data_indices[train_size:-test_size]]\n",
    "        valid_set_data = self.numeral_data[data_indices[train_size:-test_size]]\n",
    "        valid_set_labels = self.numeral_labels[data_indices[train_size:-test_size]]\n",
    "        valid_set_labels = torch.from_numpy(valid_set_labels)\n",
    "        valid_set = torch.utils.data.TensorDataset(valid_set_data, valid_set_labels)\n",
    "        self.train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "        self.test_loader = DataLoader(test_set, batch_size=64, shuffle=False)\n",
    "        self.valid_loader = DataLoader(valid_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2920,
     "status": "ok",
     "timestamp": 1730099885354,
     "user": {
      "displayName": "Leah",
      "userId": "09729964029713612593"
     },
     "user_tz": -660
    },
    "id": "3npdESj6Vb_t",
    "outputId": "0a809505-9071-4271-d3e2-6475dac2b339"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Downloaded successfully train_2000.label\n",
      "\n",
      "Sample questions and corresponding labels... \n",
      "\n",
      "['manner how did serfdom develop in and then leave russia ?', 'cremat what films featured the character popeye doyle ?', \"manner how can i find a list of celebrities ' real names ?\", 'animal what fowl grabs the spotlight after the chinese year of the monkey ?', 'exp what is the full form of .com ?']\n",
      "['DESC', 'ENTY', 'DESC', 'ENTY', 'ABBR']\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "DataManager.maybe_download(\"data\", \"train_2000.label\", \"http://cogcomp.org/Data/QA/QC/\")\n",
    "\n",
    "dm = DataManager()\n",
    "dm.read_data(\"data/\", [\"train_2000.label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304,
     "referenced_widgets": [
      "b5f11f26986f4f7f9672cda4cce4c04c",
      "6396749a89244419a5d51582152cb5c0",
      "a2b7a74f028f47818e30302243327c7f",
      "820b615a8697479bb1912c5bfbe8ab81",
      "ee4c8b7e85504077a97dea27d567fb66",
      "d552575efb1941578f158372a635ddcf",
      "e77ec73107b94dbe861a4eb620c3283e",
      "25479d347e3a46b79e56299d1312f36c",
      "de8f496094b045f4b1558a03b7e823dc",
      "435118b7b3f54b1a8737d42d5ac8a309",
      "38d3d99fe8544538ad505322ef260f2c",
      "da65e8dbf74f40a1898ebaf77f3be6bb",
      "4e785cffeb25404887625ab1d5d00bf0",
      "b07cafb34542445d9911785763b26c03",
      "de6d29af64db4de1a64b6007ef58e0e9",
      "f538fd6c8b0e4176ad653c424b1ae22c",
      "4e6f0dfe9afc4e169beb9f51c7dd32b3",
      "cd16857e4ccf461eb3b0e48c981c2a59",
      "760edc4715c64f69b8a8783e519e138d",
      "f7948d703bf94d31b6b322c015b3c00a",
      "79fda8581f8b4fd1a65b02a9f93c26d6",
      "2b644d9a974a408292cff9c83da071af",
      "267a07c2b13a446fab67a89a0cb072a5",
      "a328fc3bb5a543f19dcf9a2c9965582b",
      "c6858de49e8449b5871b536319b0dfe1",
      "16a2786eb626445caab0c0e3b0664a9a",
      "ab9c4c15bb4d49c2944f2c554577feb7",
      "63c29c27522347d69bb8f5220a1ec77c",
      "f169f1322d6a44daa93aaf6a4218ffaf",
      "2752eb073ee4435baac523f971927796",
      "b94f0f8a88fe41b7a1bc07be14d59fa5",
      "eb78c73f18334937b7822e9aa91c70a2",
      "f610d45f76b34791beac5cb332b5292a",
      "7b37033a81c74315871d16d5ddb7e934",
      "5af4eba0c7a344e3ae80ac14327e4708",
      "4d67f790359841a5b93333a7f4ed3c27",
      "469e1a49fcb34bd080fd5c81f924417a",
      "664c776c4e4b48699c7089f15d5c0816",
      "411476d7854f47cab8fd695e7677ad7b",
      "9e514947678440db984165d2f8e9c1dd",
      "8826c59432b34399ba86baf56c60e4e4",
      "d738f65f007647e7990ba39221f25bf4",
      "481c001b4f4b439e90cc27009d35eac3",
      "d1c3c48aae48409aa8defc31042fccbd"
     ]
    },
    "executionInfo": {
     "elapsed": 6331,
     "status": "ok",
     "timestamp": 1730099891683,
     "user": {
      "displayName": "Leah",
      "userId": "09729964029713612593"
     },
     "user_tz": -660
    },
    "id": "EgrYZPmyVj60",
    "outputId": "d3f6a0c6-e9d2-4f2b-cc11-ca96e239613c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f11f26986f4f7f9672cda4cce4c04c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da65e8dbf74f40a1898ebaf77f3be6bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "267a07c2b13a446fab67a89a0cb072a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b37033a81c74315871d16d5ddb7e934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dm.manipulate_data()\n",
    "dm.train_valid_test_split(train_ratio=0.8, test_ratio = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1730099892412,
     "user": {
      "displayName": "Leah",
      "userId": "09729964029713612593"
     },
     "user_tz": -660
    },
    "id": "bH-U0sUMVnW-",
    "outputId": "8f3a2cbb-4154-43a8-c44a-89285545ca0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 36]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for x, y in dm.train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPPrm2_FHj-j"
   },
   "source": [
    "We now declare the `BaseTrainer` class, which will be used later to train the subsequent deep learning models for text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1730099892413,
     "user": {
      "displayName": "Leah",
      "userId": "09729964029713612593"
     },
     "user_tz": -660
    },
    "id": "yXlNQvGn7OEb"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class BaseTrainer:\n",
    "    def __init__(self, model, criterion, optimizer, train_loader, val_loader):\n",
    "        self.model = model\n",
    "        self.criterion = criterion  #the loss function\n",
    "        self.optimizer = optimizer  #the optimizer\n",
    "        self.train_loader = train_loader  #the train loader\n",
    "        self.val_loader = val_loader  #the valid loader\n",
    "\n",
    "    #the function to train the model in many epochs\n",
    "    def fit(self, num_epochs):\n",
    "        self.num_batches = len(self.train_loader)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "            train_loss, train_accuracy = self.train_one_epoch()\n",
    "            val_loss, val_accuracy = self.validate_one_epoch()\n",
    "            print(\n",
    "                f'{self.num_batches}/{self.num_batches} - train_loss: {train_loss:.4f} - train_accuracy: {train_accuracy*100:.4f}% \\\n",
    "                - val_loss: {val_loss:.4f} - val_accuracy: {val_accuracy*100:.4f}%')\n",
    "\n",
    "    #train in one epoch, return the train_acc, train_loss\n",
    "    def train_one_epoch(self):\n",
    "        self.model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for i, data in enumerate(self.train_loader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        train_accuracy = correct / total\n",
    "        train_loss = running_loss / self.num_batches\n",
    "        return train_loss, train_accuracy\n",
    "\n",
    "    #evaluate on a loader and return the loss and accuracy\n",
    "    def evaluate(self, loader):\n",
    "        self.model.eval()\n",
    "        loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for data in loader:\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = correct / total\n",
    "        loss = loss / len(self.val_loader)\n",
    "        return loss, accuracy\n",
    "\n",
    "    #return the val_acc, val_loss, be called at the end of each epoch\n",
    "    def validate_one_epoch(self):\n",
    "      val_loss, val_accuracy = self.evaluate(self.val_loader)\n",
    "      return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sPvLRNDfoSq-"
   },
   "source": [
    "## <font color=\"#0b486b\">Part 4: Transformer-based models for sequence modeling and neural embedding</font>\n",
    "\n",
    "<div style=\"text-align: right\"><font color=\"red; font-weight:bold\">[Total marks for this part: 30 marks]<span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QOoskR7Ko6Iv"
   },
   "source": [
    "#### <font color=\"red\">**Question 4.1**</font>\n",
    "\n",
    "**Implement the multi-head attention module of the Transformer for the text classification problem. The provided code is from our tutorial. In this part, we only use the output of the Transformer encoder for the classification task. For further information on the Transformer model, refer to [this paper](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf).**\n",
    "\n",
    "<div style=\"text-align: right\"><font color=\"red; font-weight:bold\">[Total marks for this part: 10 marks]<span></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LUnK0WBspLDK"
   },
   "source": [
    "Below is the code of `MultiHeadSelfAttention`, `PositionWiseFeedForward`, `PositionalEncoding`, and `EncoderLayer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1730099892413,
     "user": {
      "displayName": "Leah",
      "userId": "09729964029713612593"
     },
     "user_tz": -660
    },
    "id": "PERuLdjTZpAl"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        # Ensure that the model dimension (d_model) is divisible by the number of heads\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "\n",
    "        # Initialize dimensions\n",
    "        self.d_model = d_model # Model's dimension\n",
    "        self.num_heads = num_heads # Number of attention heads\n",
    "        self.d_k = d_model // num_heads # Dimension of each head's key, query, and value\n",
    "\n",
    "        # Linear layers for transforming inputs\n",
    "        self.W_q = nn.Linear(d_model, d_model) # Query transformation\n",
    "        self.W_k = nn.Linear(d_model, d_model) # Key transformation\n",
    "        self.W_v = nn.Linear(d_model, d_model) # Value transformation\n",
    "        self.W_o = nn.Linear(d_model, d_model) # Output transformation\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V):\n",
    "        # Calculate attention scores\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "\n",
    "        # Apply mask if provided (useful for preventing attention to certain parts like padding)\n",
    "        #if mask is not None:\n",
    "            #attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        # Softmax is applied to obtain attention probabilities\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "\n",
    "        # Multiply by values to obtain the final output\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        # Reshape the input to have num_heads for multi-head attention\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        # Combine the multiple heads back to original shape\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "\n",
    "    def forward(self, Q, K, V):\n",
    "        # Apply linear transformations and split heads\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "\n",
    "        # Perform scaled dot-product attention\n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V)\n",
    "\n",
    "        # Combine heads and apply output transformation\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1730099892413,
     "user": {
      "displayName": "Leah",
      "userId": "09729964029713612593"
     },
     "user_tz": -660
    },
    "id": "J4MZuO59pR0T"
   },
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1730099892413,
     "user": {
      "displayName": "Leah",
      "userId": "09729964029713612593"
     },
     "user_tz": -660
    },
    "id": "qq15ROA9pV3N"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1730099892413,
     "user": {
      "displayName": "Leah",
      "userId": "09729964029713612593"
     },
     "user_tz": -660
    },
    "id": "HKaj3paKqTmG"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_output = self.self_attn(x, x, x)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pI9I1Gl1ptq8"
   },
   "source": [
    "Your task is to develop `TransformerClassifier` in which we input the embedding with the shape `[batch_size, seq_len, embed_dim]` to some `EncoderLayer` (i.e., num_layers specifies the number of EncoderLayer) and then compute the average of all token embeddings (i.e., `[batch_size, seq_len, embed_dim]`) across the `seq_len`. Finally, on the top of this average embedding, we build up a linear layer for making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1730099892413,
     "user": {
      "displayName": "Leah",
      "userId": "09729964029713612593"
     },
     "user_tz": -660
    },
    "id": "VwzVfN2dpY_p"
   },
   "outputs": [],
   "source": [
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, num_layers, dropout_rate=0.2, data_manager = None):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "        self.vocab_size = data_manager.vocab_size\n",
    "        self.num_classes = data_manager.num_classes\n",
    "        self.embed_dim = embed_dim\n",
    "        self.max_seq_len = data_manager.max_seq_len\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.embedding = None\n",
    "        self.positional_encoding = None\n",
    "        self.encoder_layers = None\n",
    "        self.classifier = None\n",
    "\n",
    "    def build(self):\n",
    "        # Define the embedding layer and positional encoding\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embed_dim)\n",
    "        self.positional_encoding = PositionalEncoding(d_model=self.embed_dim, max_seq_length=self.max_seq_len)\n",
    "\n",
    "        # Define the stack of encoder layers\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model=self.embed_dim, num_heads=self.num_heads, d_ff=self.ff_dim, dropout=self.dropout_rate)\n",
    "            for _ in range(self.num_layers)\n",
    "        ])\n",
    "\n",
    "        # Define the output classification layer\n",
    "        self.classifier = nn.Linear(self.embed_dim, self.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply embedding and positional encoding\n",
    "        x = self.embedding(x)\n",
    "        x = self.positional_encoding(x)\n",
    "\n",
    "        # Pass through each encoder layer\n",
    "        for encoder in self.encoder_layers:\n",
    "            x = encoder(x)\n",
    "\n",
    "        # Compute the average of all token embeddings across the sequence length\n",
    "        x = torch.mean(x, dim=1)  # Shape: (batch_size, embed_dim)\n",
    "\n",
    "        # Pass through the classifier to get class scores\n",
    "        output = self.classifier(x)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 142705,
     "status": "ok",
     "timestamp": 1730100035114,
     "user": {
      "displayName": "Leah",
      "userId": "09729964029713612593"
     },
     "user_tz": -660
    },
    "id": "V4sjIOzQrn3b",
    "outputId": "ae202c60-00ec-4246-9d2f-4232169a49c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "26/26 - train_loss: 2.0195 - train_accuracy: 22.4235%                 - val_loss: 0.8066 - val_accuracy: 12.6263%\n",
      "Epoch 2/30\n",
      "26/26 - train_loss: 1.7232 - train_accuracy: 18.8007%                 - val_loss: 0.8273 - val_accuracy: 12.6263%\n",
      "Epoch 3/30\n",
      "26/26 - train_loss: 1.6846 - train_accuracy: 21.9238%                 - val_loss: 0.8405 - val_accuracy: 26.2626%\n",
      "Epoch 4/30\n",
      "26/26 - train_loss: 1.6877 - train_accuracy: 21.9863%                 - val_loss: 0.7704 - val_accuracy: 27.2727%\n",
      "Epoch 5/30\n",
      "26/26 - train_loss: 1.6988 - train_accuracy: 20.8620%                 - val_loss: 0.7289 - val_accuracy: 27.2727%\n",
      "Epoch 6/30\n",
      "26/26 - train_loss: 1.6803 - train_accuracy: 21.3616%                 - val_loss: 0.7095 - val_accuracy: 27.2727%\n",
      "Epoch 7/30\n",
      "26/26 - train_loss: 1.6396 - train_accuracy: 26.2961%                 - val_loss: 0.7326 - val_accuracy: 37.3737%\n",
      "Epoch 8/30\n",
      "26/26 - train_loss: 1.4001 - train_accuracy: 37.6640%                 - val_loss: 0.7161 - val_accuracy: 47.4747%\n",
      "Epoch 9/30\n",
      "26/26 - train_loss: 1.2422 - train_accuracy: 40.4747%                 - val_loss: 0.6288 - val_accuracy: 52.0202%\n",
      "Epoch 10/30\n",
      "26/26 - train_loss: 1.2179 - train_accuracy: 43.4104%                 - val_loss: 0.6564 - val_accuracy: 52.0202%\n",
      "Epoch 11/30\n",
      "26/26 - train_loss: 1.2150 - train_accuracy: 43.4728%                 - val_loss: 0.6537 - val_accuracy: 42.9293%\n",
      "Epoch 12/30\n",
      "26/26 - train_loss: 1.2459 - train_accuracy: 43.4104%                 - val_loss: 0.6519 - val_accuracy: 52.0202%\n",
      "Epoch 13/30\n",
      "26/26 - train_loss: 1.2114 - train_accuracy: 41.9738%                 - val_loss: 0.6387 - val_accuracy: 52.0202%\n",
      "Epoch 14/30\n",
      "26/26 - train_loss: 1.2317 - train_accuracy: 43.4104%                 - val_loss: 0.6480 - val_accuracy: 52.0202%\n",
      "Epoch 15/30\n",
      "26/26 - train_loss: 1.1640 - train_accuracy: 42.1611%                 - val_loss: 0.6213 - val_accuracy: 52.0202%\n",
      "Epoch 16/30\n",
      "26/26 - train_loss: 1.1949 - train_accuracy: 43.5978%                 - val_loss: 0.6206 - val_accuracy: 52.0202%\n",
      "Epoch 17/30\n",
      "26/26 - train_loss: 1.2376 - train_accuracy: 40.9119%                 - val_loss: 0.6298 - val_accuracy: 52.0202%\n",
      "Epoch 18/30\n",
      "26/26 - train_loss: 1.2266 - train_accuracy: 42.4110%                 - val_loss: 0.6463 - val_accuracy: 42.9293%\n",
      "Epoch 19/30\n",
      "26/26 - train_loss: 1.2405 - train_accuracy: 43.7227%                 - val_loss: 0.6809 - val_accuracy: 52.0202%\n",
      "Epoch 20/30\n",
      "26/26 - train_loss: 1.2180 - train_accuracy: 42.5984%                 - val_loss: 0.6839 - val_accuracy: 52.0202%\n",
      "Epoch 21/30\n",
      "26/26 - train_loss: 1.2252 - train_accuracy: 41.9738%                 - val_loss: 0.6617 - val_accuracy: 53.5354%\n",
      "Epoch 22/30\n",
      "26/26 - train_loss: 1.2002 - train_accuracy: 41.6615%                 - val_loss: 0.6299 - val_accuracy: 48.9899%\n",
      "Epoch 23/30\n",
      "26/26 - train_loss: 1.3626 - train_accuracy: 37.4766%                 - val_loss: 0.6581 - val_accuracy: 48.9899%\n",
      "Epoch 24/30\n",
      "26/26 - train_loss: 1.3150 - train_accuracy: 41.5990%                 - val_loss: 0.6316 - val_accuracy: 48.9899%\n",
      "Epoch 25/30\n",
      "26/26 - train_loss: 1.2868 - train_accuracy: 38.7883%                 - val_loss: 0.6526 - val_accuracy: 39.8990%\n",
      "Epoch 26/30\n",
      "26/26 - train_loss: 1.2311 - train_accuracy: 42.8482%                 - val_loss: 0.6746 - val_accuracy: 48.9899%\n",
      "Epoch 27/30\n",
      "26/26 - train_loss: 1.2266 - train_accuracy: 40.7870%                 - val_loss: 0.6670 - val_accuracy: 48.9899%\n",
      "Epoch 28/30\n",
      "26/26 - train_loss: 1.2843 - train_accuracy: 41.1618%                 - val_loss: 0.6952 - val_accuracy: 48.9899%\n",
      "Epoch 29/30\n",
      "26/26 - train_loss: 1.2764 - train_accuracy: 39.4129%                 - val_loss: 0.6139 - val_accuracy: 48.9899%\n",
      "Epoch 30/30\n",
      "26/26 - train_loss: 1.2872 - train_accuracy: 42.4735%                 - val_loss: 0.6796 - val_accuracy: 48.9899%\n"
     ]
    }
   ],
   "source": [
    "transformer = TransformerClassifier(embed_dim=512, num_heads=8, ff_dim=2048, num_layers=12, dropout_rate=0.1, data_manager= dm)\n",
    "transformer.build()\n",
    "transformer = transformer.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=1e-4, betas=(0.9, 0.98), eps=1e-9)\n",
    "trainer = BaseTrainer(model= transformer, criterion=criterion, optimizer=optimizer, train_loader=dm.train_loader, val_loader=dm.valid_loader)\n",
    "trainer.fit(num_epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aMbhi0_d0NL-"
   },
   "source": [
    "#### <font color=\"red\">**Question 4.2**</font>\n",
    "**Prefix prompt-tuning with Transformers: You need to implement the prefix prompt-tuning with Transformers. Basically, we base on a pre-trained Transformer, add prefix prompts, and do fine-tuning for a target dataset.**\n",
    "\n",
    "<div style=\"text-align: right\"><font color=\"red; font-weight:bold\">[Total marks for this part: 10 marks]<span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UyecWD190TP1"
   },
   "source": [
    "To implement prefix prompt-tuning with pretrained Transformers, we first need to create the Bert dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "referenced_widgets": [
      "675917aedabb4757b29ffc5ce68d27b2",
      "271da10763c44576abb69a4bf33a3a41",
      "c76045ff401a43609f5f512048ad5367",
      "84d18616fa384dd0a42aa0acde461324",
      "25a32ee47b77405e998500c8a399e069",
      "00b39bc83f3144efb81d63157f5f3866",
      "19e348836fbf4c4aad38c640d652e0ac",
      "fdd0e87c5171473c84e154df6cc7f56d",
      "5097b153f99c4835bac0469470e09a91",
      "644db172e0f54919b5184756dfcef39e",
      "5c80d72bb04647e9ad22c686155eea43"
     ]
    },
    "executionInfo": {
     "elapsed": 758,
     "status": "ok",
     "timestamp": 1730100035870,
     "user": {
      "displayName": "Leah",
      "userId": "09729964029713612593"
     },
     "user_tz": -660
    },
    "id": "mq3PiV2UrueO",
    "outputId": "fb915bf5-20a7-4179-ee76-39c894173d12"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675917aedabb4757b29ffc5ce68d27b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 2000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer, AdamW\n",
    "from datasets import Dataset\n",
    "\n",
    "model_name = \"bert-base-uncased\"  # BERT or any similar model\n",
    "\n",
    "# Tokenize input and prepare model inputs\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "dataset = Dataset.from_dict({\"text\": dm.str_questions, \"label\": dm.numeral_labels})\n",
    "\n",
    "# Tokenize the dataset\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length= 36)\n",
    "\n",
    "dataset = dataset.map(tokenize_function, batched=True)\n",
    "dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASKOrO5n1ckY"
   },
   "source": [
    "The following function splits the BERT dataset `dataset` into three BERT datasets for training, valid, and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1730100035870,
     "user": {
      "displayName": "Leah",
      "userId": "09729964029713612593"
     },
     "user_tz": -660
    },
    "id": "UDgfnCV70gzG"
   },
   "outputs": [],
   "source": [
    "def train_valid_test_split(dataset, train_ratio=0.8, test_ratio = 0.1):\n",
    "    num_sentences = len(dataset)\n",
    "    train_size = int(num_sentences*train_ratio) +1\n",
    "    test_size = int(num_sentences*test_ratio) +1\n",
    "    valid_size = num_sentences - (train_size + test_size)\n",
    "    train_set = dataset[:train_size]\n",
    "    train_set = Dataset.from_dict(train_set)\n",
    "    train_set.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "    test_set = dataset[-test_size:]\n",
    "    test_set = Dataset.from_dict(test_set)\n",
    "    test_set.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "    valid_set = dataset[train_size:-test_size]\n",
    "    valid_set = Dataset.from_dict(valid_set)\n",
    "    valid_set.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "    train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(test_set, batch_size=64, shuffle=False)\n",
    "    valid_loader = DataLoader(valid_set, batch_size=64, shuffle=False)\n",
    "    return train_loader, test_loader, valid_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 558,
     "status": "ok",
     "timestamp": 1730100036424,
     "user": {
      "displayName": "Leah",
      "userId": "09729964029713612593"
     },
     "user_tz": -660
    },
    "id": "s_sEtXml1lT7"
   },
   "outputs": [],
   "source": [
    "train_loader, test_loader, valid_loader = train_valid_test_split(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S3jHATGX2hn4"
   },
   "source": [
    "You need to implement the class `PrefixTuningForClassification` for the prefix prompt fine-tuning. We first load a pre-trained BERT model specified by `model_name`. The parameter `prefix_length` specifies the length of the prefix prompts we add to the pre-trained BERT model. Specifically, given the input batch `[batch_size, seq_len]`, we input to the embedding layer of the pre-trained BERT model to obtain `[batch_size, seq_len, embed_size]`. We create the prefix prompts $P$ of the size `[prefix_length, embed_size]` and concatenate to the embeddings from the pre-trained BERT to obtain `[batch_size, seq_len + prefix_length, embed_size]`. This concatenation tensor will then be fed to the encoder layers of the pre-trained BERT layer to obtain the last `[batch_size, seq_len + prefix_length, embed_size]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXFogDf1jVD0"
   },
   "source": [
    "We then take mean across the seq_len to obtain `[batch_size, embed_size]` on which we can build up a linear layer for making predictions. Please note that **the parameters to tune include the prefix prompts $P$** and **the output linear layer**, and you should freeze the parameters of the BERT pre-trained model. Moreover, your code should cover the edge case when `prefix_length=None`. In this case, we do not insert any prefix prompts and we only do fine-tuning for the output linear layer on top.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1730100036424,
     "user": {
      "displayName": "Leah",
      "userId": "09729964029713612593"
     },
     "user_tz": -660
    },
    "id": "bZtGBqQV16Kj"
   },
   "outputs": [],
   "source": [
    "class PrefixTuningForClassification(nn.Module):\n",
    "    def __init__(self, model_name, prefix_length=None, data_manager=None):\n",
    "        super(PrefixTuningForClassification, self).__init__()\n",
    "\n",
    "        # Load the pretrained transformer model (e.g., BERT)\n",
    "        self.model = AutoModel.from_pretrained(model_name).to(device)\n",
    "        self.hidden_size = self.model.config.hidden_size\n",
    "        self.prefix_length = prefix_length\n",
    "        self.num_classes = data_manager.num_classes\n",
    "\n",
    "        # Define the prefix prompts and the classifier layer\n",
    "        if prefix_length is not None:\n",
    "            self.prefix_embeddings = nn.Parameter(torch.randn(prefix_length, self.hidden_size))\n",
    "        self.classifier = nn.Linear(self.hidden_size, self.num_classes)\n",
    "\n",
    "        # Freeze the parameters of the BERT model to only train the prefix embeddings and the classifier\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # Get embeddings from the BERT model\n",
    "        embeddings = self.model.embeddings(input_ids=input_ids)\n",
    "\n",
    "        if self.prefix_length is not None:\n",
    "            # Concatenate the prefix embeddings to the input embeddings\n",
    "            batch_size = embeddings.size(0)\n",
    "            prefix_expanded = self.prefix_embeddings.unsqueeze(0).expand(batch_size, -1, -1)\n",
    "            embeddings = torch.cat((prefix_expanded, embeddings), dim=1)\n",
    "\n",
    "            # Adjust the attention mask to include the prefix tokens\n",
    "            # prefix_attention_mask = torch.ones((batch_size, self.prefix_length), device=attention_mask.device)\n",
    "            # attention_mask = torch.cat((prefix_attention_mask, attention_mask), dim=1)\n",
    "            prefix_attention_mask = torch.ones((batch_size, self.prefix_length), device=attention_mask.device)\n",
    "            attention_mask = torch.cat((prefix_attention_mask, attention_mask), dim=1)\n",
    "\n",
    "        # Adjust attention mask to 4D for compatibility with BERT's self-attention\n",
    "        # extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
    "        # extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "        extended_attention_mask = attention_mask[:, None, None, :]  # (batch_size, 1, 1, seq_length)\n",
    "        extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
    "\n",
    "        # Pass through the BERT model's encoder layers with the modified attention mask\n",
    "        outputs = self.model.encoder(\n",
    "            embeddings,\n",
    "            attention_mask=extended_attention_mask\n",
    "        ).last_hidden_state\n",
    "\n",
    "        # Take the mean of the embeddings across the sequence length for classification\n",
    "        output = torch.mean(outputs, dim=1)\n",
    "        logits = self.classifier(output)\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RtYVNYXi24Os"
   },
   "source": [
    "You can use the following `FineTunedBaseTrainer` to train the prompt fine-tuning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1730100036424,
     "user": {
      "displayName": "Leah",
      "userId": "09729964029713612593"
     },
     "user_tz": -660
    },
    "id": "NmRkMqYB24tv"
   },
   "outputs": [],
   "source": [
    "class FineTunedBaseTrainer:\n",
    "    def __init__(self, model, criterion, optimizer, train_loader, val_loader):\n",
    "        self.model = model\n",
    "        self.criterion = criterion  #the loss function\n",
    "        self.optimizer = optimizer  #the optimizer\n",
    "        self.train_loader = train_loader  #the train loader\n",
    "        self.val_loader = val_loader  #the valid loader\n",
    "\n",
    "    #the function to train the model in many epochs\n",
    "    def fit(self, num_epochs):\n",
    "        self.num_batches = len(self.train_loader)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "            train_loss, train_accuracy = self.train_one_epoch()\n",
    "            val_loss, val_accuracy = self.validate_one_epoch()\n",
    "            print(\n",
    "                f'{self.num_batches}/{self.num_batches} - train_loss: {train_loss:.4f} - train_accuracy: {train_accuracy*100:.4f}% \\\n",
    "                - val_loss: {val_loss:.4f} - val_accuracy: {val_accuracy*100:.4f}%')\n",
    "\n",
    "    #train in one epoch, return the train_acc, train_loss\n",
    "    def train_one_epoch(self):\n",
    "        self.model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for batch in self.train_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(input_ids= input_ids, attention_mask= attention_mask)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        train_accuracy = correct / total\n",
    "        train_loss = running_loss / self.num_batches\n",
    "        return train_loss, train_accuracy\n",
    "\n",
    "    #evaluate on a loader and return the loss and accuracy\n",
    "    def evaluate(self, loader):\n",
    "        self.model.eval()\n",
    "        loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for batch in loader:\n",
    "                input_ids = batch[\"input_ids\"].to(device)\n",
    "                labels = batch[\"label\"].to(device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(device)\n",
    "                outputs = self.model(input_ids= input_ids, attention_mask= attention_mask)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = correct / total\n",
    "        loss = loss / len(self.val_loader)\n",
    "        return loss, accuracy\n",
    "\n",
    "    #return the val_acc, val_loss, be called at the end of each epoch\n",
    "    def validate_one_epoch(self):\n",
    "      val_loss, val_accuracy = self.evaluate(self.val_loader)\n",
    "      return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4KQhBHPe20zo"
   },
   "source": [
    "We declare and train the prefix-prompt tuning model. In addition, you need to be patient with this model because it might converge slowly with many epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "0dd56eca004b498c8e8a3a4e75cc9d85",
      "ed102189e0b24e9ca834857bd0ebf0d3",
      "ccd194b3f22f4b37b8d3f182002e07a6",
      "e76c00f399d842cc8706081d2d7c496e",
      "f28f54dd3bd1410db3894c98d3fc7b8f",
      "6eab916b446f46f69737e7db92ae5495",
      "fd119bf2e6974e57a1024b070765a208",
      "5d3f0237c7cf4c698938db8148515d72",
      "d40c21b6df2b4cd88a93cdbf111f8473",
      "38ecfb648c8640f98259ec528286235c",
      "47782585cba342c0a9af20cd706fb893"
     ]
    },
    "executionInfo": {
     "elapsed": 3521,
     "status": "ok",
     "timestamp": 1730100039943,
     "user": {
      "displayName": "Leah",
      "userId": "09729964029713612593"
     },
     "user_tz": -660
    },
    "id": "qLowEOeg3HWW",
    "outputId": "252f889b-364d-4052-cd5c-456d078e3c57"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dd56eca004b498c8e8a3a4e75cc9d85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prefix_tuning_model = PrefixTuningForClassification(model_name = \"bert-base-uncased\", prefix_length = 5, data_manager = dm).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 769380,
     "status": "ok",
     "timestamp": 1730100809321,
     "user": {
      "displayName": "Leah",
      "userId": "09729964029713612593"
     },
     "user_tz": -660
    },
    "id": "UYMDOjWW3UVk",
    "outputId": "f9bf4143-127c-4feb-e807-e91089ce0a87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "26/26 - train_loss: 1.7438 - train_accuracy: 21.5490%                 - val_loss: 0.8787 - val_accuracy: 18.1818%\n",
      "Epoch 2/100\n",
      "26/26 - train_loss: 1.7187 - train_accuracy: 24.2973%                 - val_loss: 0.8615 - val_accuracy: 23.7374%\n",
      "Epoch 3/100\n",
      "26/26 - train_loss: 1.6804 - train_accuracy: 26.2961%                 - val_loss: 0.8482 - val_accuracy: 26.2626%\n",
      "Epoch 4/100\n",
      "26/26 - train_loss: 1.6622 - train_accuracy: 26.6708%                 - val_loss: 0.8375 - val_accuracy: 27.2727%\n",
      "Epoch 5/100\n",
      "26/26 - train_loss: 1.6456 - train_accuracy: 28.7320%                 - val_loss: 0.8240 - val_accuracy: 28.7879%\n",
      "Epoch 6/100\n",
      "26/26 - train_loss: 1.6304 - train_accuracy: 30.2936%                 - val_loss: 0.8159 - val_accuracy: 30.3030%\n",
      "Epoch 7/100\n",
      "26/26 - train_loss: 1.6279 - train_accuracy: 31.6052%                 - val_loss: 0.8085 - val_accuracy: 32.8283%\n",
      "Epoch 8/100\n",
      "26/26 - train_loss: 1.6006 - train_accuracy: 34.2911%                 - val_loss: 0.7997 - val_accuracy: 36.3636%\n",
      "Epoch 9/100\n",
      "26/26 - train_loss: 1.5885 - train_accuracy: 34.1037%                 - val_loss: 0.7943 - val_accuracy: 36.3636%\n",
      "Epoch 10/100\n",
      "26/26 - train_loss: 1.5728 - train_accuracy: 37.3517%                 - val_loss: 0.7834 - val_accuracy: 42.9293%\n",
      "Epoch 11/100\n",
      "26/26 - train_loss: 1.5712 - train_accuracy: 42.1611%                 - val_loss: 0.7809 - val_accuracy: 43.4343%\n",
      "Epoch 12/100\n",
      "26/26 - train_loss: 1.5509 - train_accuracy: 44.7220%                 - val_loss: 0.7735 - val_accuracy: 46.9697%\n",
      "Epoch 13/100\n",
      "26/26 - train_loss: 1.5439 - train_accuracy: 46.3460%                 - val_loss: 0.7632 - val_accuracy: 47.9798%\n",
      "Epoch 14/100\n",
      "26/26 - train_loss: 1.5275 - train_accuracy: 49.1568%                 - val_loss: 0.7619 - val_accuracy: 50.5051%\n",
      "Epoch 15/100\n",
      "26/26 - train_loss: 1.5175 - train_accuracy: 50.5309%                 - val_loss: 0.7576 - val_accuracy: 48.9899%\n",
      "Epoch 16/100\n",
      "26/26 - train_loss: 1.5227 - train_accuracy: 48.2823%                 - val_loss: 0.7531 - val_accuracy: 47.4747%\n",
      "Epoch 17/100\n",
      "26/26 - train_loss: 1.4930 - train_accuracy: 48.9694%                 - val_loss: 0.7456 - val_accuracy: 50.0000%\n",
      "Epoch 18/100\n",
      "26/26 - train_loss: 1.4898 - train_accuracy: 51.2804%                 - val_loss: 0.7356 - val_accuracy: 52.5253%\n",
      "Epoch 19/100\n",
      "26/26 - train_loss: 1.4905 - train_accuracy: 52.4672%                 - val_loss: 0.7315 - val_accuracy: 53.5354%\n",
      "Epoch 20/100\n",
      "26/26 - train_loss: 1.4670 - train_accuracy: 53.7164%                 - val_loss: 0.7281 - val_accuracy: 54.5455%\n",
      "Epoch 21/100\n",
      "26/26 - train_loss: 1.4675 - train_accuracy: 53.5290%                 - val_loss: 0.7239 - val_accuracy: 54.5455%\n",
      "Epoch 22/100\n",
      "26/26 - train_loss: 1.4587 - train_accuracy: 55.8401%                 - val_loss: 0.7234 - val_accuracy: 59.0909%\n",
      "Epoch 23/100\n",
      "26/26 - train_loss: 1.4522 - train_accuracy: 59.4628%                 - val_loss: 0.7212 - val_accuracy: 62.1212%\n",
      "Epoch 24/100\n",
      "26/26 - train_loss: 1.4322 - train_accuracy: 60.7121%                 - val_loss: 0.7148 - val_accuracy: 65.1515%\n",
      "Epoch 25/100\n",
      "26/26 - train_loss: 1.4180 - train_accuracy: 63.8976%                 - val_loss: 0.7077 - val_accuracy: 67.1717%\n",
      "Epoch 26/100\n",
      "26/26 - train_loss: 1.4101 - train_accuracy: 64.7096%                 - val_loss: 0.6974 - val_accuracy: 66.6667%\n",
      "Epoch 27/100\n",
      "26/26 - train_loss: 1.4061 - train_accuracy: 63.8976%                 - val_loss: 0.6929 - val_accuracy: 66.1616%\n",
      "Epoch 28/100\n",
      "26/26 - train_loss: 1.4019 - train_accuracy: 62.5234%                 - val_loss: 0.6879 - val_accuracy: 67.6768%\n",
      "Epoch 29/100\n",
      "26/26 - train_loss: 1.3932 - train_accuracy: 65.3342%                 - val_loss: 0.6780 - val_accuracy: 67.6768%\n",
      "Epoch 30/100\n",
      "26/26 - train_loss: 1.3870 - train_accuracy: 64.0849%                 - val_loss: 0.6749 - val_accuracy: 67.6768%\n",
      "Epoch 31/100\n",
      "26/26 - train_loss: 1.3612 - train_accuracy: 67.3954%                 - val_loss: 0.6728 - val_accuracy: 69.1919%\n",
      "Epoch 32/100\n",
      "26/26 - train_loss: 1.3572 - train_accuracy: 67.5203%                 - val_loss: 0.6725 - val_accuracy: 69.1919%\n",
      "Epoch 33/100\n",
      "26/26 - train_loss: 1.3678 - train_accuracy: 67.0206%                 - val_loss: 0.6675 - val_accuracy: 70.7071%\n",
      "Epoch 34/100\n",
      "26/26 - train_loss: 1.3689 - train_accuracy: 68.3948%                 - val_loss: 0.6610 - val_accuracy: 70.7071%\n",
      "Epoch 35/100\n",
      "26/26 - train_loss: 1.3283 - train_accuracy: 69.8938%                 - val_loss: 0.6551 - val_accuracy: 72.2222%\n",
      "Epoch 36/100\n",
      "26/26 - train_loss: 1.3220 - train_accuracy: 69.4566%                 - val_loss: 0.6457 - val_accuracy: 72.2222%\n",
      "Epoch 37/100\n",
      "26/26 - train_loss: 1.3237 - train_accuracy: 70.1437%                 - val_loss: 0.6415 - val_accuracy: 72.7273%\n",
      "Epoch 38/100\n",
      "26/26 - train_loss: 1.3131 - train_accuracy: 69.7064%                 - val_loss: 0.6329 - val_accuracy: 73.2323%\n",
      "Epoch 39/100\n",
      "26/26 - train_loss: 1.3054 - train_accuracy: 70.2061%                 - val_loss: 0.6299 - val_accuracy: 74.7475%\n",
      "Epoch 40/100\n",
      "26/26 - train_loss: 1.2964 - train_accuracy: 72.5172%                 - val_loss: 0.6280 - val_accuracy: 75.2525%\n",
      "Epoch 41/100\n",
      "26/26 - train_loss: 1.2928 - train_accuracy: 71.4553%                 - val_loss: 0.6278 - val_accuracy: 74.7475%\n",
      "Epoch 42/100\n",
      "26/26 - train_loss: 1.3527 - train_accuracy: 74.8282%                 - val_loss: 0.6232 - val_accuracy: 74.2424%\n",
      "Epoch 43/100\n",
      "26/26 - train_loss: 1.2732 - train_accuracy: 73.3292%                 - val_loss: 0.6179 - val_accuracy: 75.2525%\n",
      "Epoch 44/100\n",
      "26/26 - train_loss: 1.2575 - train_accuracy: 74.5784%                 - val_loss: 0.6140 - val_accuracy: 76.2626%\n",
      "Epoch 45/100\n",
      "26/26 - train_loss: 1.2595 - train_accuracy: 74.8907%                 - val_loss: 0.6109 - val_accuracy: 77.2727%\n",
      "Epoch 46/100\n",
      "26/26 - train_loss: 1.2386 - train_accuracy: 74.7033%                 - val_loss: 0.6069 - val_accuracy: 76.2626%\n",
      "Epoch 47/100\n",
      "26/26 - train_loss: 1.2397 - train_accuracy: 74.5159%                 - val_loss: 0.6024 - val_accuracy: 76.2626%\n",
      "Epoch 48/100\n",
      "26/26 - train_loss: 1.2101 - train_accuracy: 74.2661%                 - val_loss: 0.5990 - val_accuracy: 76.7677%\n",
      "Epoch 49/100\n",
      "26/26 - train_loss: 1.2173 - train_accuracy: 74.6408%                 - val_loss: 0.5906 - val_accuracy: 76.2626%\n",
      "Epoch 50/100\n",
      "26/26 - train_loss: 1.2021 - train_accuracy: 74.4535%                 - val_loss: 0.5823 - val_accuracy: 76.7677%\n",
      "Epoch 51/100\n",
      "26/26 - train_loss: 1.2116 - train_accuracy: 74.9532%                 - val_loss: 0.5809 - val_accuracy: 77.2727%\n",
      "Epoch 52/100\n",
      "26/26 - train_loss: 1.1933 - train_accuracy: 74.4535%                 - val_loss: 0.5808 - val_accuracy: 78.7879%\n",
      "Epoch 53/100\n",
      "26/26 - train_loss: 1.1921 - train_accuracy: 74.3910%                 - val_loss: 0.5767 - val_accuracy: 77.7778%\n",
      "Epoch 54/100\n",
      "26/26 - train_loss: 1.1752 - train_accuracy: 73.7039%                 - val_loss: 0.5730 - val_accuracy: 77.2727%\n",
      "Epoch 55/100\n",
      "26/26 - train_loss: 1.1511 - train_accuracy: 75.2655%                 - val_loss: 0.5638 - val_accuracy: 77.2727%\n",
      "Epoch 56/100\n",
      "26/26 - train_loss: 1.1941 - train_accuracy: 75.2655%                 - val_loss: 0.5560 - val_accuracy: 76.7677%\n",
      "Epoch 57/100\n",
      "26/26 - train_loss: 1.1724 - train_accuracy: 76.0775%                 - val_loss: 0.5576 - val_accuracy: 78.7879%\n",
      "Epoch 58/100\n",
      "26/26 - train_loss: 1.1492 - train_accuracy: 77.4516%                 - val_loss: 0.5521 - val_accuracy: 80.3030%\n",
      "Epoch 59/100\n",
      "26/26 - train_loss: 1.1354 - train_accuracy: 76.1399%                 - val_loss: 0.5454 - val_accuracy: 80.3030%\n",
      "Epoch 60/100\n",
      "26/26 - train_loss: 1.1298 - train_accuracy: 77.5765%                 - val_loss: 0.5410 - val_accuracy: 81.3131%\n",
      "Epoch 61/100\n",
      "26/26 - train_loss: 1.1180 - train_accuracy: 77.4516%                 - val_loss: 0.5390 - val_accuracy: 80.8081%\n",
      "Epoch 62/100\n",
      "26/26 - train_loss: 1.1019 - train_accuracy: 77.5141%                 - val_loss: 0.5364 - val_accuracy: 80.3030%\n",
      "Epoch 63/100\n",
      "26/26 - train_loss: 1.0968 - train_accuracy: 77.5765%                 - val_loss: 0.5347 - val_accuracy: 80.8081%\n",
      "Epoch 64/100\n",
      "26/26 - train_loss: 1.0937 - train_accuracy: 78.5134%                 - val_loss: 0.5340 - val_accuracy: 81.3131%\n",
      "Epoch 65/100\n",
      "26/26 - train_loss: 1.1084 - train_accuracy: 77.0768%                 - val_loss: 0.5338 - val_accuracy: 80.8081%\n",
      "Epoch 66/100\n",
      "26/26 - train_loss: 1.0814 - train_accuracy: 77.5765%                 - val_loss: 0.5346 - val_accuracy: 79.7980%\n",
      "Epoch 67/100\n",
      "26/26 - train_loss: 1.0930 - train_accuracy: 78.5134%                 - val_loss: 0.5314 - val_accuracy: 79.2929%\n",
      "Epoch 68/100\n",
      "26/26 - train_loss: 1.0508 - train_accuracy: 78.5759%                 - val_loss: 0.5225 - val_accuracy: 82.3232%\n",
      "Epoch 69/100\n",
      "26/26 - train_loss: 1.0512 - train_accuracy: 78.5134%                 - val_loss: 0.5206 - val_accuracy: 82.3232%\n",
      "Epoch 70/100\n",
      "26/26 - train_loss: 1.0554 - train_accuracy: 79.3879%                 - val_loss: 0.5142 - val_accuracy: 82.3232%\n",
      "Epoch 71/100\n",
      "26/26 - train_loss: 1.0449 - train_accuracy: 78.3885%                 - val_loss: 0.5100 - val_accuracy: 82.8283%\n",
      "Epoch 72/100\n",
      "26/26 - train_loss: 1.0516 - train_accuracy: 79.5753%                 - val_loss: 0.5074 - val_accuracy: 82.8283%\n",
      "Epoch 73/100\n",
      "26/26 - train_loss: 1.0509 - train_accuracy: 78.5759%                 - val_loss: 0.5040 - val_accuracy: 81.3131%\n",
      "Epoch 74/100\n",
      "26/26 - train_loss: 1.0241 - train_accuracy: 77.6390%                 - val_loss: 0.5011 - val_accuracy: 81.8182%\n",
      "Epoch 75/100\n",
      "26/26 - train_loss: 1.0451 - train_accuracy: 78.5134%                 - val_loss: 0.4967 - val_accuracy: 81.8182%\n",
      "Epoch 76/100\n",
      "26/26 - train_loss: 1.0009 - train_accuracy: 78.2636%                 - val_loss: 0.4896 - val_accuracy: 81.8182%\n",
      "Epoch 77/100\n",
      "26/26 - train_loss: 1.0053 - train_accuracy: 78.3885%                 - val_loss: 0.4820 - val_accuracy: 82.3232%\n",
      "Epoch 78/100\n",
      "26/26 - train_loss: 0.9972 - train_accuracy: 79.1380%                 - val_loss: 0.4822 - val_accuracy: 82.8283%\n",
      "Epoch 79/100\n",
      "26/26 - train_loss: 0.9996 - train_accuracy: 79.0131%                 - val_loss: 0.4777 - val_accuracy: 81.8182%\n",
      "Epoch 80/100\n",
      "26/26 - train_loss: 0.9832 - train_accuracy: 79.0756%                 - val_loss: 0.4726 - val_accuracy: 83.3333%\n",
      "Epoch 81/100\n",
      "26/26 - train_loss: 0.9715 - train_accuracy: 79.6377%                 - val_loss: 0.4661 - val_accuracy: 83.3333%\n",
      "Epoch 82/100\n",
      "26/26 - train_loss: 0.9726 - train_accuracy: 79.9500%                 - val_loss: 0.4663 - val_accuracy: 83.3333%\n",
      "Epoch 83/100\n",
      "26/26 - train_loss: 0.9983 - train_accuracy: 80.1374%                 - val_loss: 0.4658 - val_accuracy: 84.3434%\n",
      "Epoch 84/100\n",
      "26/26 - train_loss: 0.9512 - train_accuracy: 79.4503%                 - val_loss: 0.4626 - val_accuracy: 83.3333%\n",
      "Epoch 85/100\n",
      "26/26 - train_loss: 0.9536 - train_accuracy: 79.1380%                 - val_loss: 0.4597 - val_accuracy: 82.8283%\n",
      "Epoch 86/100\n",
      "26/26 - train_loss: 0.9764 - train_accuracy: 79.0756%                 - val_loss: 0.4569 - val_accuracy: 82.8283%\n",
      "Epoch 87/100\n",
      "26/26 - train_loss: 0.9660 - train_accuracy: 79.6377%                 - val_loss: 0.4533 - val_accuracy: 82.8283%\n",
      "Epoch 88/100\n",
      "26/26 - train_loss: 0.9762 - train_accuracy: 79.5753%                 - val_loss: 0.4545 - val_accuracy: 82.8283%\n",
      "Epoch 89/100\n",
      "26/26 - train_loss: 0.9378 - train_accuracy: 79.2630%                 - val_loss: 0.4537 - val_accuracy: 83.8384%\n",
      "Epoch 90/100\n",
      "26/26 - train_loss: 0.9431 - train_accuracy: 79.8876%                 - val_loss: 0.4442 - val_accuracy: 83.8384%\n",
      "Epoch 91/100\n",
      "26/26 - train_loss: 0.9322 - train_accuracy: 79.8251%                 - val_loss: 0.4406 - val_accuracy: 83.3333%\n",
      "Epoch 92/100\n",
      "26/26 - train_loss: 0.9140 - train_accuracy: 81.1993%                 - val_loss: 0.4363 - val_accuracy: 83.8384%\n",
      "Epoch 93/100\n",
      "26/26 - train_loss: 0.9095 - train_accuracy: 80.0125%                 - val_loss: 0.4345 - val_accuracy: 84.3434%\n",
      "Epoch 94/100\n",
      "26/26 - train_loss: 0.9130 - train_accuracy: 80.5122%                 - val_loss: 0.4311 - val_accuracy: 84.3434%\n",
      "Epoch 95/100\n",
      "26/26 - train_loss: 0.8956 - train_accuracy: 80.5746%                 - val_loss: 0.4290 - val_accuracy: 84.8485%\n",
      "Epoch 96/100\n",
      "26/26 - train_loss: 0.8780 - train_accuracy: 79.8876%                 - val_loss: 0.4216 - val_accuracy: 84.8485%\n",
      "Epoch 97/100\n",
      "26/26 - train_loss: 0.8897 - train_accuracy: 81.0119%                 - val_loss: 0.4198 - val_accuracy: 84.8485%\n",
      "Epoch 98/100\n",
      "26/26 - train_loss: 0.8602 - train_accuracy: 81.2617%                 - val_loss: 0.4155 - val_accuracy: 84.8485%\n",
      "Epoch 99/100\n",
      "26/26 - train_loss: 0.8673 - train_accuracy: 80.6996%                 - val_loss: 0.4099 - val_accuracy: 84.3434%\n",
      "Epoch 100/100\n",
      "26/26 - train_loss: 0.8879 - train_accuracy: 80.9494%                 - val_loss: 0.4089 - val_accuracy: 85.3535%\n"
     ]
    }
   ],
   "source": [
    "# Set up the optimizer based on the presence of prefix tuning\n",
    "if prefix_tuning_model.prefix_length is not None:\n",
    "    optimizer = torch.optim.Adam(list(prefix_tuning_model.classifier.parameters()) + [prefix_tuning_model.prefix_embeddings], lr=5e-5)\n",
    "else:\n",
    "    optimizer = torch.optim.Adam(prefix_tuning_model.classifier.parameters(), lr=1e-4)\n",
    "\n",
    "# Set up the loss function and trainer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "trainer = FineTunedBaseTrainer(\n",
    "    model=prefix_tuning_model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=valid_loader\n",
    ")\n",
    "\n",
    "# Train the model for the specified number of epochs\n",
    "trainer.fit(num_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xi6PnvdO-Glw"
   },
   "source": [
    "#### <font color=\"red\">**Question 4.3**</font>\n",
    "**For any models defined in the previous questions (of all parts), you are free to fine-tune hyperparameters, e.g., `optimizer`, `learning_rate`, `state_sizes`, such that you get a best model, i.e., the one with the highest accuracy on the test set. You will need to report (i) what is your best model,  (ii) its accuracy on the test set, and (iii) the values of its hyperparameters. Note that you must report your best model's accuracy with rounding to 4 decimal places, i.e., 0.xxxx. You will also need to upload your best model (or provide us with the link to download your best model). The assessment will be based on your best model's accuracy, with up to 9 marks available, specifically:**\n",
    "* The best accuracy $\\ge$ 0.97: 10 marks\n",
    "* 0.97 $>$ The best accuracy $\\ge$ 0.92: 7 marks\n",
    "* 0.92 $>$ The best accuracy $\\ge$ 0.85: 4 marks\n",
    "* The best accuracy $<$ 0.85: 0 mark\n",
    "\n",
    "**For this question, you can put below the code to train the best model. In this case, you need to show your code and the evidence of running regarding the best model. Moreover, if you save the best model, you need to provide the link to download the best model, the code to load the best model, and then evaluate on the test set.**\n",
    "<div style=\"text-align: right\"><font color=\"red\">[10 marks]</font></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EvM2pq3J-K0C"
   },
   "source": [
    "# Give your answer here.\n",
    "\n",
    "(i) What is your best model?\n",
    "\n",
    "(ii) The accuracy of your best model on the validation set\n",
    "\n",
    "(iii) The values of the hyperparameters of your best model\n",
    "\n",
    "(iv) The link to download your best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lvn-cCajx5ck"
   },
   "source": [
    "(i) The RNN with Initialized Embedding and Fine-tuning is my best-performing model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKwYt7rJx6xv"
   },
   "source": [
    "(ii)The RNN with Initialized Embedding and Fine-tuning achieved the highest final validation accuracy at 0.9848."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jL83jyX1zqM2"
   },
   "source": [
    "(iii) Hyperparameters for the Best Model (RNN with Initialized Embedding and Fine-tuning):\n",
    "\n",
    "Cell Type: GRU\n",
    "Embedding Size: 128 (set from the pretrained embedding model)\n",
    "\n",
    "State Sizes: [64, 128] (two RNN layers with hidden sizes 64 and 128, respectively)\n",
    "\n",
    "Output Type: Mean\n",
    "\n",
    "Pretrained Embedding Model: Glove-Wiki-Gigaword-100\n",
    "\n",
    "Run Mode: init-fine-tune (embedding matrix initialized from pretrained model and fine-tuned)\n",
    "\n",
    "Optimizer: Adam\n",
    "\n",
    "Learning Rate: 0.001\n",
    "\n",
    "Criterion (Loss Function): CrossEntropyLoss\n",
    "\n",
    "Number of Epochs: 30\n",
    "\n",
    "Batch Size: 64 (from data loader configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wIC0KxBCDs1Z"
   },
   "outputs": [],
   "source": [
    "# My best model: RNN with initialized embedding and fine-tuning model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# RNN Model with initialized embedding and fine-tuning\n",
    "class RNN(BaseRNN):\n",
    "    def __init__(self, cell_type='gru', embed_size=128, state_sizes=[64, 128], output_type='mean',\n",
    "                 data_manager=None, run_mode='init-fine-tune', embed_model='glove-wiki-gigaword-100'):\n",
    "        super().__init__(cell_type, embed_size, state_sizes, output_type, data_manager)\n",
    "        self.run_mode = run_mode\n",
    "        self.embed_model = embed_model\n",
    "\n",
    "        if self.run_mode != 'scratch':\n",
    "            self.embed_size = int(self.embed_model.split(\"-\")[-1])\n",
    "\n",
    "        self.word2idx = data_manager.word2idx\n",
    "        self.vocab_size = data_manager.vocab_size\n",
    "        self.embed_matrix = np.zeros(shape=[self.vocab_size, self.embed_size])\n",
    "        self.build_embedding_matrix()\n",
    "\n",
    "    def build_embedding_matrix(self):\n",
    "        # Load pretrained embedding model (e.g., GloVe)\n",
    "        print(f\"Loading the embedding model: {self.embed_model}...\")\n",
    "        wv = KeyedVectors.load_word2vec_format(f'{self.embed_model}.txt', binary=False)  # Replace with the model path if needed\n",
    "        for word, idx in self.word2idx.items():\n",
    "            if word in wv:\n",
    "                self.embed_matrix[idx] = wv[word]\n",
    "            else:\n",
    "                self.embed_matrix[idx] = np.random.normal(scale=0.6, size=(self.embed_size,))\n",
    "        print(\"Embedding matrix built and saved successfully.\")\n",
    "\n",
    "    def build(self):\n",
    "        # Build RNN layers\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(self.embed_matrix), freeze=(self.run_mode == 'init-only'))\n",
    "        self.rnn = getattr(nn, self.cell_type.upper())(self.embed_size, self.state_sizes[0], batch_first=True)\n",
    "        self.fc = nn.Linear(self.state_sizes[-1], self.data_manager.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        output, _ = self.rnn(x)\n",
    "        if self.output_type == 'mean':\n",
    "            output = torch.mean(output, dim=1)\n",
    "        return self.fc(output)\n",
    "\n",
    "# Define parameters\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dm = DataManager()  # Assuming `DataManager` object is created for loading data and vocabulary\n",
    "rnn_init_fine_tune = RNN(\n",
    "    cell_type='gru',\n",
    "    embed_size=128,\n",
    "    state_sizes=[64, 128],\n",
    "    output_type='mean',\n",
    "    data_manager=dm,\n",
    "    run_mode='init-fine-tune',\n",
    "    embed_model='glove-wiki-gigaword-100'\n",
    ").to(device)\n",
    "\n",
    "# Training Setup\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(rnn_init_fine_tune.parameters(), lr=0.001)\n",
    "\n",
    "trainer = BaseTrainer(\n",
    "    model=rnn_init_fine_tune,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=dm.train_loader,\n",
    "    val_loader=dm.valid_loader\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(num_epochs=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "evYeSuXm-OkM"
   },
   "source": [
    "---\n",
    "<div style=\"text-align: center\"> <font color=\"green\">GOOD LUCK WITH YOUR ASSIGNMENT 2!</font> </div>\n",
    "<div style=\"text-align: center\"> <font color=\"black\">END OF ASSIGNMENT</font> </div>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1JfMZeCkkvjZ5LvKNV-UnR10pl-RogMgF",
     "timestamp": 1728355302391
    },
    {
     "file_id": "1kZnS4MhgMkovuS2rij76tYrcBqr9xmE0",
     "timestamp": 1726366756850
    },
    {
     "file_id": "1O9BBAQ6DMy0p3r33BWf8_oTf_540FHvY",
     "timestamp": 1726028905396
    },
    {
     "file_id": "1-A2k9TxxkkwzlDrgE0K6gfFX4qglIsHC",
     "timestamp": 1725714854288
    },
    {
     "file_id": "1YiJPJe5vvMNzzDAfp9QGCGQMSkT8Rdky",
     "timestamp": 1725706067748
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python [conda env:mamba-codegeex-agent]",
   "language": "python",
   "name": "conda-env-mamba-codegeex-agent-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00b39bc83f3144efb81d63157f5f3866": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0dd56eca004b498c8e8a3a4e75cc9d85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ed102189e0b24e9ca834857bd0ebf0d3",
       "IPY_MODEL_ccd194b3f22f4b37b8d3f182002e07a6",
       "IPY_MODEL_e76c00f399d842cc8706081d2d7c496e"
      ],
      "layout": "IPY_MODEL_f28f54dd3bd1410db3894c98d3fc7b8f"
     }
    },
    "16a2786eb626445caab0c0e3b0664a9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eb78c73f18334937b7822e9aa91c70a2",
      "placeholder": "​",
      "style": "IPY_MODEL_f610d45f76b34791beac5cb332b5292a",
      "value": " 466k/466k [00:00&lt;00:00, 2.14MB/s]"
     }
    },
    "19e348836fbf4c4aad38c640d652e0ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "25479d347e3a46b79e56299d1312f36c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25a32ee47b77405e998500c8a399e069": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "267a07c2b13a446fab67a89a0cb072a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a328fc3bb5a543f19dcf9a2c9965582b",
       "IPY_MODEL_c6858de49e8449b5871b536319b0dfe1",
       "IPY_MODEL_16a2786eb626445caab0c0e3b0664a9a"
      ],
      "layout": "IPY_MODEL_ab9c4c15bb4d49c2944f2c554577feb7"
     }
    },
    "271da10763c44576abb69a4bf33a3a41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_00b39bc83f3144efb81d63157f5f3866",
      "placeholder": "​",
      "style": "IPY_MODEL_19e348836fbf4c4aad38c640d652e0ac",
      "value": "Map: 100%"
     }
    },
    "2752eb073ee4435baac523f971927796": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b644d9a974a408292cff9c83da071af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "38d3d99fe8544538ad505322ef260f2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "38ecfb648c8640f98259ec528286235c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "411476d7854f47cab8fd695e7677ad7b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "435118b7b3f54b1a8737d42d5ac8a309": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "469e1a49fcb34bd080fd5c81f924417a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_481c001b4f4b439e90cc27009d35eac3",
      "placeholder": "​",
      "style": "IPY_MODEL_d1c3c48aae48409aa8defc31042fccbd",
      "value": " 570/570 [00:00&lt;00:00, 13.0kB/s]"
     }
    },
    "47782585cba342c0a9af20cd706fb893": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "481c001b4f4b439e90cc27009d35eac3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d67f790359841a5b93333a7f4ed3c27": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8826c59432b34399ba86baf56c60e4e4",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d738f65f007647e7990ba39221f25bf4",
      "value": 570
     }
    },
    "4e6f0dfe9afc4e169beb9f51c7dd32b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e785cffeb25404887625ab1d5d00bf0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e6f0dfe9afc4e169beb9f51c7dd32b3",
      "placeholder": "​",
      "style": "IPY_MODEL_cd16857e4ccf461eb3b0e48c981c2a59",
      "value": "vocab.txt: 100%"
     }
    },
    "5097b153f99c4835bac0469470e09a91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5af4eba0c7a344e3ae80ac14327e4708": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_411476d7854f47cab8fd695e7677ad7b",
      "placeholder": "​",
      "style": "IPY_MODEL_9e514947678440db984165d2f8e9c1dd",
      "value": "config.json: 100%"
     }
    },
    "5c80d72bb04647e9ad22c686155eea43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5d3f0237c7cf4c698938db8148515d72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6396749a89244419a5d51582152cb5c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d552575efb1941578f158372a635ddcf",
      "placeholder": "​",
      "style": "IPY_MODEL_e77ec73107b94dbe861a4eb620c3283e",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "63c29c27522347d69bb8f5220a1ec77c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "644db172e0f54919b5184756dfcef39e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "664c776c4e4b48699c7089f15d5c0816": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "675917aedabb4757b29ffc5ce68d27b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_271da10763c44576abb69a4bf33a3a41",
       "IPY_MODEL_c76045ff401a43609f5f512048ad5367",
       "IPY_MODEL_84d18616fa384dd0a42aa0acde461324"
      ],
      "layout": "IPY_MODEL_25a32ee47b77405e998500c8a399e069"
     }
    },
    "6eab916b446f46f69737e7db92ae5495": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "760edc4715c64f69b8a8783e519e138d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79fda8581f8b4fd1a65b02a9f93c26d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b37033a81c74315871d16d5ddb7e934": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5af4eba0c7a344e3ae80ac14327e4708",
       "IPY_MODEL_4d67f790359841a5b93333a7f4ed3c27",
       "IPY_MODEL_469e1a49fcb34bd080fd5c81f924417a"
      ],
      "layout": "IPY_MODEL_664c776c4e4b48699c7089f15d5c0816"
     }
    },
    "820b615a8697479bb1912c5bfbe8ab81": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_435118b7b3f54b1a8737d42d5ac8a309",
      "placeholder": "​",
      "style": "IPY_MODEL_38d3d99fe8544538ad505322ef260f2c",
      "value": " 48.0/48.0 [00:00&lt;00:00, 879B/s]"
     }
    },
    "84d18616fa384dd0a42aa0acde461324": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_644db172e0f54919b5184756dfcef39e",
      "placeholder": "​",
      "style": "IPY_MODEL_5c80d72bb04647e9ad22c686155eea43",
      "value": " 2000/2000 [00:00&lt;00:00, 9343.31 examples/s]"
     }
    },
    "8826c59432b34399ba86baf56c60e4e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e514947678440db984165d2f8e9c1dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a2b7a74f028f47818e30302243327c7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_25479d347e3a46b79e56299d1312f36c",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_de8f496094b045f4b1558a03b7e823dc",
      "value": 48
     }
    },
    "a328fc3bb5a543f19dcf9a2c9965582b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_63c29c27522347d69bb8f5220a1ec77c",
      "placeholder": "​",
      "style": "IPY_MODEL_f169f1322d6a44daa93aaf6a4218ffaf",
      "value": "tokenizer.json: 100%"
     }
    },
    "ab9c4c15bb4d49c2944f2c554577feb7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b07cafb34542445d9911785763b26c03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_760edc4715c64f69b8a8783e519e138d",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f7948d703bf94d31b6b322c015b3c00a",
      "value": 231508
     }
    },
    "b5f11f26986f4f7f9672cda4cce4c04c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6396749a89244419a5d51582152cb5c0",
       "IPY_MODEL_a2b7a74f028f47818e30302243327c7f",
       "IPY_MODEL_820b615a8697479bb1912c5bfbe8ab81"
      ],
      "layout": "IPY_MODEL_ee4c8b7e85504077a97dea27d567fb66"
     }
    },
    "b94f0f8a88fe41b7a1bc07be14d59fa5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c6858de49e8449b5871b536319b0dfe1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2752eb073ee4435baac523f971927796",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b94f0f8a88fe41b7a1bc07be14d59fa5",
      "value": 466062
     }
    },
    "c76045ff401a43609f5f512048ad5367": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fdd0e87c5171473c84e154df6cc7f56d",
      "max": 2000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5097b153f99c4835bac0469470e09a91",
      "value": 2000
     }
    },
    "ccd194b3f22f4b37b8d3f182002e07a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d3f0237c7cf4c698938db8148515d72",
      "max": 440449768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d40c21b6df2b4cd88a93cdbf111f8473",
      "value": 440449768
     }
    },
    "cd16857e4ccf461eb3b0e48c981c2a59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d1c3c48aae48409aa8defc31042fccbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d40c21b6df2b4cd88a93cdbf111f8473": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d552575efb1941578f158372a635ddcf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d738f65f007647e7990ba39221f25bf4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "da65e8dbf74f40a1898ebaf77f3be6bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4e785cffeb25404887625ab1d5d00bf0",
       "IPY_MODEL_b07cafb34542445d9911785763b26c03",
       "IPY_MODEL_de6d29af64db4de1a64b6007ef58e0e9"
      ],
      "layout": "IPY_MODEL_f538fd6c8b0e4176ad653c424b1ae22c"
     }
    },
    "de6d29af64db4de1a64b6007ef58e0e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_79fda8581f8b4fd1a65b02a9f93c26d6",
      "placeholder": "​",
      "style": "IPY_MODEL_2b644d9a974a408292cff9c83da071af",
      "value": " 232k/232k [00:00&lt;00:00, 4.80MB/s]"
     }
    },
    "de8f496094b045f4b1558a03b7e823dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e76c00f399d842cc8706081d2d7c496e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_38ecfb648c8640f98259ec528286235c",
      "placeholder": "​",
      "style": "IPY_MODEL_47782585cba342c0a9af20cd706fb893",
      "value": " 440M/440M [00:02&lt;00:00, 227MB/s]"
     }
    },
    "e77ec73107b94dbe861a4eb620c3283e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eb78c73f18334937b7822e9aa91c70a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed102189e0b24e9ca834857bd0ebf0d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6eab916b446f46f69737e7db92ae5495",
      "placeholder": "​",
      "style": "IPY_MODEL_fd119bf2e6974e57a1024b070765a208",
      "value": "model.safetensors: 100%"
     }
    },
    "ee4c8b7e85504077a97dea27d567fb66": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f169f1322d6a44daa93aaf6a4218ffaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f28f54dd3bd1410db3894c98d3fc7b8f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f538fd6c8b0e4176ad653c424b1ae22c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f610d45f76b34791beac5cb332b5292a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f7948d703bf94d31b6b322c015b3c00a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fd119bf2e6974e57a1024b070765a208": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fdd0e87c5171473c84e154df6cc7f56d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
