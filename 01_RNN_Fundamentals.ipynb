{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LsB3OmMxB4Dh"
   },
   "source": [
    "## Section 1: Fundamentals in RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c83ea5R9nh_y"
   },
   "source": [
    "You need to **manually** implement a multi-timestep Recurrent Neural Network that can take an input as a 3D tensor `[batch_size, seq_len, input_size]` for a classification task.\n",
    "\n",
    "<div style=\"text-align: right\"><font color=\"red\">[Total: 10 marks]</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OzH6RTIjExy2"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yKlCx1D3rczS"
   },
   "source": [
    "We declare the relevant variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C77pPiGBA9IJ"
   },
   "outputs": [],
   "source": [
    "input_size = 5\n",
    "seq_len = 4\n",
    "batch_size = 8\n",
    "hidden_size = 3\n",
    "num_classes = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A10tCeyKrkUt"
   },
   "source": [
    "We create random inputs (i.e., `inputs`) and random labels (i.e., `random_labels`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ybfqj-wBEu0H",
    "outputId": "910494eb-5a3c-491d-f893-1c924ce627aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 5])\n",
      "tensor([1, 1, 1, 2, 2, 1, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.randn(batch_size, seq_len, input_size)\n",
    "random_labels = torch.randint(0, num_classes, (batch_size,))\n",
    "print(inputs.shape)\n",
    "print(random_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I7ABTPhyr6wa"
   },
   "source": [
    "(1) In what follows, we need to declare the model parameters, which include the matrices $U$ (``[input_size, hidden_size]``), W (``[hidden_size, hidden_size]``), $V$ (``[hidden_size, num_classes]``) and the biases $b$ and $c$ for the hidden states and logits respectively.\n",
    "\n",
    "<div style=\"text-align: right\"><font color=\"red\">[2 marks]</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qzlZtACzsbSR"
   },
   "outputs": [],
   "source": [
    "# Initialize model parameters\n",
    "U = torch.randn(input_size, hidden_size, requires_grad=True)  # Input to hidden\n",
    "W = torch.randn(hidden_size, hidden_size, requires_grad=True)  # Hidden to hidden\n",
    "V = torch.randn(hidden_size, num_classes, requires_grad=True)  # Hidden to output\n",
    "b = torch.zeros(hidden_size, requires_grad=True)  # Bias for hidden state\n",
    "c = torch.zeros(num_classes, requires_grad=True)  # Bias for logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MW_gal7Us9fK"
   },
   "source": [
    "(2) Next you need to write the code to compute `hiddens` which is a 3D tensor of the shape ``[batch_size, seq_len, hidden_size]`` using the formula of the simple/standard RNN cells. You can freely modify the code below.\n",
    "\n",
    "<div style=\"text-align: right\"><font color=\"red\">[2 marks]</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KwxqdXkTtaea",
    "outputId": "642a3770-6514-4428-82a7-e37027b4f0ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.8084,  0.9821,  0.8073],\n",
      "         [ 0.9938, -0.9555,  0.7075],\n",
      "         [ 0.4055, -0.9929,  0.9969],\n",
      "         [ 0.9945, -0.9910,  0.8921]],\n",
      "\n",
      "        [[ 0.0532,  0.9440,  0.2912],\n",
      "         [-0.4986,  0.9506, -0.7748],\n",
      "         [-0.7442, -0.9991, -0.9967],\n",
      "         [-0.9792, -0.5459, -0.5721]],\n",
      "\n",
      "        [[-0.8725,  0.3214, -0.7466],\n",
      "         [-0.8302, -0.9683,  0.3266],\n",
      "         [-0.5712,  0.8078,  0.8800],\n",
      "         [ 0.9999, -0.9469,  0.9990]],\n",
      "\n",
      "        [[ 1.0000, -0.1361,  0.9989],\n",
      "         [ 1.0000, -0.2740,  0.9986],\n",
      "         [-0.9996,  0.8255, -0.9945],\n",
      "         [-0.4371, -1.0000,  0.9985]],\n",
      "\n",
      "        [[ 0.9578, -0.3522,  0.4308],\n",
      "         [-0.5824,  0.0759, -0.9854],\n",
      "         [-0.9950, -0.3336, -0.9489],\n",
      "         [-0.5506,  0.9973, -0.9959]],\n",
      "\n",
      "        [[ 0.9999,  0.9941,  0.9936],\n",
      "         [-0.9996, -0.5347, -0.9847],\n",
      "         [ 0.9979, -0.8326,  0.8821],\n",
      "         [ 0.9998,  0.9408,  0.8707]],\n",
      "\n",
      "        [[-0.9778, -0.3619, -0.5486],\n",
      "         [-0.9975, -0.9909, -0.9328],\n",
      "         [ 0.9895, -0.9406,  0.3484],\n",
      "         [-0.1555, -0.9362,  0.0149]],\n",
      "\n",
      "        [[ 0.9984,  0.3010,  0.9872],\n",
      "         [ 0.9867, -0.9679,  0.9797],\n",
      "         [ 1.0000,  0.9993,  0.9720],\n",
      "         [-0.9965, -0.2885, -0.8851]]], grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "#Initialize hiddens for update.\n",
    "hiddens = torch.zeros(batch_size, seq_len, hidden_size)\n",
    "\n",
    "#Insert your code here\n",
    "h_t = torch.zeros(batch_size, hidden_size)\n",
    "# Loop through each time step in the sequence\n",
    "for t in range(seq_len):\n",
    "    x_t = inputs[:, t, :]  # Input at time step t\n",
    "    h_t = torch.tanh(x_t @ U + h_t @ W + b)  # Compute next hidden state\n",
    "    hiddens[:, t, :] = h_t  # Store hidden state for this time step\n",
    "print(hiddens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sC3gaFvLtyUW"
   },
   "source": [
    "(3) In what follows, you need to write the code to compute the logits based on the last hidden state (``[batch_size, hidden_size]``) of hiddens.\n",
    "\n",
    "<div style=\"text-align: right\"><font color=\"red\">[1 mark]</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Psr-vrw8uCMN",
    "outputId": "accca9f5-4062-4272-8073-c5298d977af4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.4187,  1.3505, -1.8277],\n",
      "        [ 1.0086, -1.3806, -0.2787],\n",
      "        [-2.6241,  1.4043, -1.6980],\n",
      "        [-2.5619, -0.2007, -0.4485],\n",
      "        [ 2.6146, -0.8975,  1.3598],\n",
      "        [-1.4530,  1.5681,  1.0422],\n",
      "        [-0.4685, -0.2738, -1.2464],\n",
      "        [ 1.7942, -1.4959, -0.0793]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "logits = hiddens[:, -1, :] @ V + c  # Using the last time step's hidden state\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DEJQQz9uKFb"
   },
   "source": [
    "(4) Write the code to compute the cross-entropy loss by comparing the logits to the labels. You can use PyTorch's built-in loss function.\n",
    "\n",
    "<div style=\"text-align: right\"><font color=\"red\">[1 mark]</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gyy7lbacuWPR",
    "outputId": "f1e5d299-1179-45a3-c4c8-e26b66cfe6ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8605, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Insert your code here\n",
    "# Compute cross-entropy loss\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "loss = criterion(logits, random_labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RVt-977bumET"
   },
   "source": [
    "(5) Next, you need to do back-propagation to compute the gradients of the loss w.r.t. the model parameters. You can use PyTorch's built-in method to compute the gradients.\n",
    "\n",
    "<div style=\"text-align: right\"><font color=\"red\">[2 marks]</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HSpeFroAu6oO"
   },
   "outputs": [],
   "source": [
    "#Insert your code here\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEkHFzOovBx1"
   },
   "source": [
    "(6) Finally, let assume that the learning rate $\\eta = 0.1$, you need to write the code to **manually** update the new model parameters using the SGD manner.\n",
    "\n",
    "<div style=\"text-align: right\"><font color=\"red\">[2 marks]</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2zFSfys8wMqs"
   },
   "outputs": [],
   "source": [
    "#Insert your code here\n",
    "# Learning rate\n",
    "eta = 0.1\n",
    "\n",
    "# Update parameters manually using gradients\n",
    "with torch.no_grad():\n",
    "    U -= eta * U.grad\n",
    "    W -= eta * W.grad\n",
    "    V -= eta * V.grad\n",
    "    b -= eta * b.grad\n",
    "    c -= eta * c.grad\n",
    "\n",
    "    # Zero the gradients after updating\n",
    "    U.grad.zero_()\n",
    "    W.grad.zero_()\n",
    "    V.grad.zero_()\n",
    "    b.grad.zero_()\n",
    "    c.grad.zero_()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAVPM0BnTdd4"
   },
   "source": [
    "## Section 2: Deep Learning for Sequential Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FAgUSME4TsCP"
   },
   "source": [
    "### <font color=\"#0b486b\">Set random seeds</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "00nhh4IRUcGX"
   },
   "source": [
    "We start with importing PyTorch and NumPy and setting random seeds for PyTorch and NumPy. You can use any seeds you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O7XWUry0JXCc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import BertTokenizer\n",
    "import os\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ZoWqunmUY7L"
   },
   "outputs": [],
   "source": [
    "def seed_all(seed=1029):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU.\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "seed_all(seed=1234)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6VU1jS6SUl8q"
   },
   "source": [
    "## <font color=\"#0b486b\">Download and preprocess the data</font>\n",
    "\n",
    "<div style=\"text-align: right\"><font color=\"red; font-weight:bold\"><span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQEzWmZjUulL"
   },
   "source": [
    "The dataset we use for this assignment is a question classification dataset for which the training set consists of $5,500$ questions belonging to 6 coarse question categories including:\n",
    "- abbreviation (ABBR),\n",
    "- entity (ENTY),\n",
    "- description (DESC),\n",
    "- human (HUM),\n",
    "- location (LOC) and\n",
    "- numeric (NUM).\n",
    "\n",
    "In this assignment, we will utilize a subset of this dataset, containing $2,000$ questions for training and validation. We will use 80% of those 2000 questions for trainning and the rest for validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zOd49RTpUxxj"
   },
   "source": [
    "Preprocessing data is a crucial initial step in any machine learning or deep learning project. The *TextDataManager* class simplifies the process by providing functionalities to download and preprocess data specifically designed for the subsequent questions in this assignment. It is highly recommended to gain a comprehensive understanding of the class's functionality by **carefully reading** the content provided in the *TextDataManager* class before proceeding to answer the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_C2fuJNzUhha"
   },
   "outputs": [],
   "source": [
    "class DataManager:\n",
    "    \"\"\"\n",
    "    This class manages and preprocesses a simple text dataset for a sentence classification task.\n",
    "\n",
    "    Attributes:\n",
    "        verbose (bool): Controls verbosity for printing information during data processing.\n",
    "        max_sentence_len (int): The maximum length of a sentence in the dataset.\n",
    "        str_questions (list): A list to store the string representations of the questions in the dataset.\n",
    "        str_labels (list): A list to store the string representations of the labels in the dataset.\n",
    "        numeral_labels (list): A list to store the numerical representations of the labels in the dataset.\n",
    "        numeral_data (list): A list to store the numerical representations of the questions in the dataset.\n",
    "        random_state (int): Seed value for random number generation to ensure reproducibility.\n",
    "            Set this value to a specific integer to reproduce the same random sequence every time. Defaults to 6789.\n",
    "        random (np.random.RandomState): Random number generator object initialized with the given random_state.\n",
    "            It is used for various random operations in the class.\n",
    "\n",
    "    Methods:\n",
    "        maybe_download(dir_name, file_name, url, verbose=True):\n",
    "            Downloads a file from a given URL if it does not exist in the specified directory.\n",
    "            The directory and file are created if they do not exist.\n",
    "\n",
    "        read_data(dir_name, file_names):\n",
    "            Reads data from files in a directory, preprocesses it, and computes the maximum sentence length.\n",
    "            Each file is expected to contain rows in the format \"<label>:<question>\".\n",
    "            The labels and questions are stored as string representations.\n",
    "\n",
    "        manipulate_data():\n",
    "            Performs data manipulation by tokenizing, numericalizing, and padding the text data.\n",
    "            The questions are tokenized and converted into numerical sequences using a tokenizer.\n",
    "            The sequences are padded or truncated to the maximum sequence length.\n",
    "\n",
    "        train_valid_test_split(train_ratio=0.9):\n",
    "            Splits the data into training, validation, and test sets based on a given ratio.\n",
    "            The data is randomly shuffled, and the specified ratio is used to determine the size of the training set.\n",
    "            The string questions, numerical data, and numerical labels are split accordingly.\n",
    "            TensorFlow `Dataset` objects are created for the training and validation sets.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, verbose=True, random_state=6789):\n",
    "        self.verbose = verbose\n",
    "        self.max_sentence_len = 0\n",
    "        self.str_questions = list()\n",
    "        self.str_labels = list()\n",
    "        self.numeral_labels = list()\n",
    "        self.maxlen = None\n",
    "        self.numeral_data = list()\n",
    "        self.random_state = random_state\n",
    "        self.random = np.random.RandomState(random_state)\n",
    "\n",
    "    @staticmethod\n",
    "    def maybe_download(dir_name, file_name, url, verbose=True):\n",
    "        if not os.path.exists(dir_name):\n",
    "            os.mkdir(dir_name)\n",
    "        if not os.path.exists(os.path.join(dir_name, file_name)):\n",
    "            urlretrieve(url + file_name, os.path.join(dir_name, file_name))\n",
    "        if verbose:\n",
    "            print(\"Downloaded successfully {}\".format(file_name))\n",
    "\n",
    "    def read_data(self, dir_name, file_names):\n",
    "        self.str_questions = list()\n",
    "        self.str_labels = list()\n",
    "        for file_name in file_names:\n",
    "            file_path= os.path.join(dir_name, file_name)\n",
    "            with open(file_path, \"r\", encoding=\"latin-1\") as f:\n",
    "                for row in f:\n",
    "                    row_str = row.split(\":\")\n",
    "                    label, question = row_str[0], row_str[1]\n",
    "                    question = question.lower()\n",
    "                    self.str_labels.append(label)\n",
    "                    self.str_questions.append(question[0:-1])\n",
    "                    if self.max_sentence_len < len(self.str_questions[-1]):\n",
    "                        self.max_sentence_len = len(self.str_questions[-1])\n",
    "\n",
    "        # turns labels into numbers\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(self.str_labels)\n",
    "        self.numeral_labels = np.array(le.transform(self.str_labels))\n",
    "        self.str_classes = le.classes_\n",
    "        self.num_classes = len(self.str_classes)\n",
    "        if self.verbose:\n",
    "            print(\"\\nSample questions and corresponding labels... \\n\")\n",
    "            print(self.str_questions[0:5])\n",
    "            print(self.str_labels[0:5])\n",
    "\n",
    "    def manipulate_data(self):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        vocab = self.tokenizer.get_vocab()\n",
    "        self.word2idx = {w: i for i, w in enumerate(vocab)}\n",
    "        self.idx2word = {i:w for w,i in self.word2idx.items()}\n",
    "        self.vocab_size = len(self.word2idx)\n",
    "\n",
    "        token_ids = []\n",
    "        num_seqs = []\n",
    "        for text in self.str_questions:  # iterate over the list of text\n",
    "          text_seqs = self.tokenizer.tokenize(str(text))  # tokenize each text individually\n",
    "          # Convert tokens to IDs\n",
    "          token_ids = self.tokenizer.convert_tokens_to_ids(text_seqs)\n",
    "          # Convert token IDs to a tensor of indices using your word2idx mapping\n",
    "          seq_tensor = torch.LongTensor(token_ids)\n",
    "          num_seqs.append(seq_tensor)  # append the tensor for each sequence\n",
    "\n",
    "        # Pad the sequences and create a tensor\n",
    "        if num_seqs:\n",
    "          self.numeral_data = pad_sequence(num_seqs, batch_first=True)  # Pads to max length of the sequences\n",
    "          self.num_sentences, self.maxlen = self.numeral_data.shape\n",
    "\n",
    "    def train_valid_test_split(self, train_ratio=0.8, test_ratio = 0.1):\n",
    "        train_size = int(self.num_sentences*train_ratio) +1\n",
    "        test_size = int(self.num_sentences*test_ratio) +1\n",
    "        valid_size = self.num_sentences - (train_size + test_size)\n",
    "        data_indices = list(range(self.num_sentences))\n",
    "        random.shuffle(data_indices)\n",
    "        self.train_str_questions = [self.str_questions[i] for i in data_indices[:train_size]]\n",
    "        self.train_numeral_labels = self.numeral_labels[data_indices[:train_size]]\n",
    "        train_set_data = self.numeral_data[data_indices[:train_size]]\n",
    "        train_set_labels = self.numeral_labels[data_indices[:train_size]]\n",
    "        train_set_labels = torch.from_numpy(train_set_labels)\n",
    "        train_set = torch.utils.data.TensorDataset(train_set_data, train_set_labels)\n",
    "        self.test_str_questions = [self.str_questions[i] for i in data_indices[-test_size:]]\n",
    "        self.test_numeral_labels = self.numeral_labels[data_indices[-test_size:]]\n",
    "        test_set_data = self.numeral_data[data_indices[-test_size:]]\n",
    "        test_set_labels = self.numeral_labels[data_indices[-test_size:]]\n",
    "        test_set_labels = torch.from_numpy(test_set_labels)\n",
    "        test_set = torch.utils.data.TensorDataset(test_set_data, test_set_labels)\n",
    "        self.valid_str_questions = [self.str_questions[i] for i in data_indices[train_size:-test_size]]\n",
    "        self.valid_numeral_labels = self.numeral_labels[data_indices[train_size:-test_size]]\n",
    "        valid_set_data = self.numeral_data[data_indices[train_size:-test_size]]\n",
    "        valid_set_labels = self.numeral_labels[data_indices[train_size:-test_size]]\n",
    "        valid_set_labels = torch.from_numpy(valid_set_labels)\n",
    "        valid_set = torch.utils.data.TensorDataset(valid_set_data, valid_set_labels)\n",
    "        self.train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "        self.test_loader = DataLoader(test_set, batch_size=64, shuffle=False)\n",
    "        self.valid_loader = DataLoader(valid_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3npdESj6Vb_t",
    "outputId": "5b9b3466-7400-47b5-f48c-73c79d4a4d6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Downloaded successfully train_2000.label\n",
      "\n",
      "Sample questions and corresponding labels... \n",
      "\n",
      "['manner how did serfdom develop in and then leave russia ?', 'cremat what films featured the character popeye doyle ?', \"manner how can i find a list of celebrities ' real names ?\", 'animal what fowl grabs the spotlight after the chinese year of the monkey ?', 'exp what is the full form of .com ?']\n",
      "['DESC', 'ENTY', 'DESC', 'ENTY', 'ABBR']\n"
     ]
    }
   ],
   "source": [
    "print('Loading data...')\n",
    "DataManager.maybe_download(\"data\", \"train_2000.label\", \"http://cogcomp.org/Data/QA/QC/\")\n",
    "\n",
    "dm = DataManager()\n",
    "dm.read_data(\"data/\", [\"train_2000.label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434,
     "referenced_widgets": [
      "50cee50f3442475c80feced314145282",
      "ce9e9eebd38544f5b25b98a0e2cdf34c",
      "af621002a3084382970b6b411c765efd",
      "fe1d0c8f685243dfbc6e243fa5671239",
      "87ddbec7ee2b475aa6433b0af006e690",
      "3586e1b95c204a8f9ce03c69d03452aa",
      "721f087bb68e4adeb1a9a0732b83d735",
      "a756e535702c4f0285f9821eece1dd68",
      "ce1a58065c734481990ed9214270319a",
      "45d9d7f9ac224478b56701c7a3f507a0",
      "5b5c118d653d482fbc529152e891bed9",
      "cd58168653b84dbcaadcd8be386b07d4",
      "cfb730e25de348da9ea60e3b60efaf52",
      "cd90f84da1034182b5bc09619d36425e",
      "cd5bd48749f947d1bf5a4e8c9f95c993",
      "33a8ee2c2fc241e6be761c0adbb6f812",
      "7b2401a4710044b29da4222ca8a61da9",
      "5b8b88361e2a4d1897574cd59c6b0d76",
      "b330fcb1039542c5a9c05b1c99b882a2",
      "8e48e0022ad94e79ae79d3efaa1c10bd",
      "d577812b012440949879a174567faa9d",
      "c246219a569b4b949f35d797b6d9c3f0",
      "bdb7b835bbfe47d8910cd1c0e37c8fb7",
      "6dbb51e48bf04353955a4183f59294fb",
      "73188d0e6e2d485d9326233d8e1e65b2",
      "43850453eb604bd7a5433c4c69c951a4",
      "1fae6119720c4674ba6bb515fed454d3",
      "6a60ae03c3784a7da5648c5169383ab2",
      "54eae932f71d433197317c8b601bb10f",
      "8f40e6d522a4473383e66111101348ed",
      "7ca8e7cb308d4784a96b7f06ca0ba1aa",
      "6d5a5bec95544fb6be49b6df7bec2f08",
      "b047c36d76a74476a6ea8955ec16e74d",
      "53ab4df9ff3d40289a61fefed1be62b2",
      "1959329e8d6943389b2afb3de07991bd",
      "092596ba1aff4156abaf7c4551ef4b90",
      "9d6eef5c1fb64392b12dba68370671e6",
      "e9c7a604175f4d899b5deefb5adb0aac",
      "3f691af8ecb14909a2156bb27ee6ad48",
      "d6f3f6ce1b0041b9830a487909629025",
      "088877c46d6b4b24a8174c06af291d80",
      "4c8dd3ea42994f449a4cbdcefbdf3667",
      "542e549dd3bc4b6a839ded3923a99904",
      "639688ae9f8c4009ac1c2c89e531686f"
     ]
    },
    "id": "EgrYZPmyVj60",
    "outputId": "ded95f11-da49-4a72-8c02-a4ee6dc71b9d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50cee50f3442475c80feced314145282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd58168653b84dbcaadcd8be386b07d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb7b835bbfe47d8910cd1c0e37c8fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ab4df9ff3d40289a61fefed1be62b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dm.manipulate_data()\n",
    "dm.train_valid_test_split(train_ratio=0.8, test_ratio = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bH-U0sUMVnW-",
    "outputId": "9fe7841f-a037-462c-faa5-0d62341dcfc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 36]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for x, y in dm.train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "frFf7-ehVvNM"
   },
   "source": [
    "## <font color=\"#0b486b\">Part 1: Using Word2Vect to transform texts to vectors </font>\n",
    "\n",
    "<div style=\"text-align: right\"><font color=\"red; font-weight:bold\">[Total marks for this part: 10 marks]<span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KZFrETlMVq7P"
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JH-f1BJY9bw"
   },
   "source": [
    "#### <font color=\"red\">**Question 1.1**</font>\n",
    "**Write code to download the pretrained model *glove-wiki-gigaword-100*. Note that this model transforms a word in its dictionary to a $100$ dimensional vector.**\n",
    "\n",
    "**Write code for the function *get_word_vector(word, model)* used to transform a word to a vector using the pretrained Word2Vect model *model*. Note that for a word not in the vocabulary of our *word2vect*, you need to return a vector $0$ with 100 dimensions.**\n",
    "\n",
    "<div style=\"text-align: right\"><font color=\"red\">[2 marks]</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b76lh_hZVyac",
    "outputId": "32cb3687-0d41-40ed-ab02-fc86737ab108"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "word2vect = api.load(\"glove-wiki-gigaword-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GpbibKfdZB-S"
   },
   "outputs": [],
   "source": [
    "def get_word_vector(word, model):\n",
    "    try:\n",
    "        vector = model[word]#Insert your code\n",
    "    except KeyError:\n",
    "        vector = torch.zeros(100)#Insert your code\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8TjRdyTg2_dN"
   },
   "source": [
    "#### <font color=\"red\">**Question 1.2**</font>\n",
    "\n",
    "**Write the code for the function `get_sentence_vector(sentence, important_score=None, model= None)`. Note that this function will transform a sentence to a 100-dimensional vector using the pretrained model *model*. In addition, the list *important_score* which has the same length as the *sentence* specifies the important scores of the words in the sentence. In your code, you first need to apply *softmax* function over *important_score* to obtain the important weight *important_weight* which forms a probability over the words of the sentence. Furthermore, the final vector of the sentence will be weighted sum of the individual vectors for words and the weights in *important_weight*.**\n",
    "- $important\\_weight = softmax(important\\_score)$.\n",
    "- $final\\_vector= important\\_weight[1]\\times v[1] + important\\_weight[2]\\times v[2] + ...+ important\\_weight[T]\\times v[T]$ where $T$ is the length of the sentence and $v[i]$ is the vector representation of the $i-th$  word in this sentence.\n",
    "\n",
    "**Note that if `important_score=None` is set by default, your function should return the average of all representation vectors corresponding to set `important_score=[1,1,...,1]`.**\n",
    "\n",
    "<div style=\"text-align: right\"><font color=\"red\">[2 marks]</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MaPs4Hqa2_30"
   },
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "\n",
    "def get_sentence_vector(sentence, important_score=None, model=None):\n",
    "    # Convert words to vectors\n",
    "    word_vectors = np.array([get_word_vector(word, model) for word in sentence])\n",
    "\n",
    "    # If no important_score is provided, assign uniform weights\n",
    "    if important_score is None:\n",
    "        important_score = np.ones(len(sentence))\n",
    "\n",
    "    # Apply softmax to the importance scores to get importance weights\n",
    "    important_weight = softmax(important_score)\n",
    "\n",
    "    # Compute the weighted sum of the word vectors\n",
    "    sentence_vector = np.dot(important_weight, word_vectors)\n",
    "\n",
    "    return sentence_vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tu63GJ2c3IgZ"
   },
   "source": [
    "#### <font color=\"red\">**Question 1.3**</font>\n",
    "\n",
    "**Write code to transform questions in *dm.train_str_questions* and *dm.valid_str_questions* to feature vectors. Note that after running the following cells, you must have $X\\_train$ and $X\\_valid$ which are two NumPy arrays of the feature vectors and $y\\_train$ and $y\\_valid$ which are two arrays of numeric labels (Hint: *dm.train_numeral_labels* and *dm.valid_numeral_labels*). You can add more lines to the following cells if necessary. In addition, you should decide the *important_score* by yourself. For example, the 1st score is 1, the 2nd score is decayed by 0.9, the 3rd is decayed by 0.9, and so on.**\n",
    "\n",
    "<div style=\"text-align: right\"><font color=\"red\">[2 marks]</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5SCsWIdZ3I4S",
    "outputId": "2804b9fd-2996-401b-dbf2-a1c1842a54cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform training set to feature vectors...\n"
     ]
    }
   ],
   "source": [
    "print(\"Transform training set to feature vectors...\")\n",
    "X_train = np.array([get_sentence_vector(sentence, model=word2vect) for sentence in dm.train_str_questions])#Insert your code\n",
    "y_train = dm.train_numeral_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2odznptZ3Nf_",
    "outputId": "1afae48d-7c4f-46c3-9770-aedc11edb868"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform validation set to feature vectors...\n"
     ]
    }
   ],
   "source": [
    "print(\"Transform validation set to feature vectors...\")\n",
    "X_valid = np.array([get_sentence_vector(sentence, model=word2vect) for sentence in dm.valid_str_questions])#Insert your code\n",
    "y_valid = dm.valid_numeral_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gOp_gy3d3Reh"
   },
   "source": [
    "#### <font color=\"red\">**Question 1.4**</font>\n",
    "\n",
    "**It is now to use *MinMaxScaler(feature_range=(-1,1))* in scikit-learn to scale both training and validation sets to the range $(-1,1)$.**\n",
    "\n",
    "<div style=\"text-align: right\"><font color=\"red\">[2 marks]</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eT47Q13c3VJV",
    "outputId": "21eabc9f-3e43-4df6-e083-23a16fafa737"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1601, 100) (198, 100)\n"
     ]
    }
   ],
   "source": [
    "#Insert your code\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize MinMaxScaler with feature range (-1,1)\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "# Scale the training and validation sets\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "\n",
    "print(X_train_scaled.shape, X_valid_scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcvKQyHO3ZJx"
   },
   "source": [
    "#### <font color=\"red\">**Question 1.5**</font>\n",
    "**Train a Logistic Regression model on the training set and then evaluate on the validation set.** You can use any classification metrics in `sklearn` for evaluation.\n",
    "<div style=\"text-align: right\"><font color=\"red\">[2 marks]</font></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IQYE_rz-3b25",
    "outputId": "d96931d5-49c7-4add-d5bf-a92cad97ecb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 45.96%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80         2\n",
      "           1       0.47      0.42      0.44        36\n",
      "           2       0.46      0.48      0.47        54\n",
      "           3       0.46      0.54      0.50        52\n",
      "           4       0.48      0.48      0.48        29\n",
      "           5       0.35      0.24      0.29        25\n",
      "\n",
      "    accuracy                           0.46       198\n",
      "   macro avg       0.48      0.53      0.50       198\n",
      "weighted avg       0.45      0.46      0.45       198\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "# Initialize and train logistic regression model\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "logistic_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred = logistic_model.predict(X_valid_scaled)\n",
    "\n",
    "# Evaluate the model using accuracy\n",
    "accuracy = accuracy_score(y_valid, y_pred)\n",
    "print(f'Validation Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# You can also print additional metrics\n",
    "print(metrics.classification_report(y_valid, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZs9Y0rl7gBH"
   },
   "source": [
    "We now declare the `BaseTrainer` class, which will be used later to train the subsequent deep learning models for text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yXlNQvGn7OEb"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class BaseTrainer:\n",
    "    def __init__(self, model, criterion, optimizer, train_loader, val_loader):\n",
    "        self.model = model\n",
    "        self.criterion = criterion  #the loss function\n",
    "        self.optimizer = optimizer  #the optimizer\n",
    "        self.train_loader = train_loader  #the train loader\n",
    "        self.val_loader = val_loader  #the valid loader\n",
    "\n",
    "    #the function to train the model in many epochs\n",
    "    def fit(self, num_epochs):\n",
    "        self.num_batches = len(self.train_loader)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "            train_loss, train_accuracy = self.train_one_epoch()\n",
    "            val_loss, val_accuracy = self.validate_one_epoch()\n",
    "            print(\n",
    "                f'{self.num_batches}/{self.num_batches} - train_loss: {train_loss:.4f} - train_accuracy: {train_accuracy*100:.4f}% \\\n",
    "                - val_loss: {val_loss:.4f} - val_accuracy: {val_accuracy*100:.4f}%')\n",
    "\n",
    "    #train in one epoch, return the train_acc, train_loss\n",
    "    def train_one_epoch(self):\n",
    "        self.model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for i, data in enumerate(self.train_loader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(inputs)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        train_accuracy = correct / total\n",
    "        train_loss = running_loss / self.num_batches\n",
    "        return train_loss, train_accuracy\n",
    "\n",
    "    #evaluate on a loader and return the loss and accuracy\n",
    "    def evaluate(self, loader):\n",
    "        self.model.eval()\n",
    "        loss, correct, total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for data in loader:\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = correct / total\n",
    "        loss = loss / len(self.val_loader)\n",
    "        return loss, accuracy\n",
    "\n",
    "    #return the val_acc, val_loss, be called at the end of each epoch\n",
    "    def validate_one_epoch(self):\n",
    "      val_loss, val_accuracy = self.evaluate(self.val_loader)\n",
    "      return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3GWOQN_S7p4V"
   },
   "source": [
    "## <font color=\"#0b486b\">Part 2: Text CNN for sequence modeling and neural embedding </font>\n",
    "\n",
    "<div style=\"text-align: right\"><font color=\"red; font-weight:bold\">[Total marks for this part: 10 marks]<span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJub3Fwm7vC7"
   },
   "source": [
    "**In what follows, you are required to complete the code for Text CNN for sentence classification. The paper of Text CNN can be found at this [link](https://www.aclweb.org/anthology/D14-1181.pdf). Here is the description of the Text CNN that you need to construct.**\n",
    "- There are three attributes (properties or instance variables): *embed_size, state_size, data_manager*.\n",
    "  - `embed_size`: the dimension of the vector space for which the words are embedded to using the embedding matrix.\n",
    "  - `state_size`: the number of filters used in *Conv1D* (reference [here](https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html)).\n",
    "  - `data_manager`: the data manager to store information of the dataset.\n",
    "- The detail of the computational process is as follows:\n",
    "  - Given input $x$, we embed $x$ using the embedding matrix to obtain an $3D$ tensor $[batch\\_size, seq\\_len, embed\\_size]$ as $e$.\n",
    "  - We feed $e$ to three *Conv1D* layers, each of which has $state\\_size$ filters, activation= $relu$, and $kernel\\_size= 3, 5, 7$ respectively to obtain $h1, h2, h3$. Note that each $h1, h2, h3$ is a 3D tensor with the shape $[batch\\_size, state\\_size, output\\_size]$. Moreover, you need to apply *Conv1D* to the $seq\\_len$ dimension.\n",
    "  - We then apply *GlobalMaxPool1D()* (reference [here](https://pytorch.org/docs/stable/generated/torch.nn.functional.max_pool1d.html#torch.nn.functional.max_pool1d)) over $h1, h2, h3$ to obtain 2D tensors stored in $h1, h2, h3$ again.\n",
    "  - We then concatenate three 2D tensors $h1, h2, h3$ to obtain $h$ with the shape $\\left[batch\\_size, 3\\times state\\_size\\right]$. Note that you need to specify the axis to concatenate.\n",
    "  - We finally build up one dense layer $\\left[3\\times state\\_size, num\\_classes\\right]$  on the top of $h$ for classification.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lEnG-BGJ239k"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#You can modify the code if you want but need to keep the skeleton\n",
    "class TextCNN(torch.nn.Module):\n",
    "    def __init__(self, embed_size= 128, state_size=16, data_manager=None):\n",
    "        super().__init__()\n",
    "        self.data_manager = data_manager\n",
    "        self.embed_size = embed_size\n",
    "        self.state_size = state_size\n",
    "        #declare the necessary layers here\n",
    "        self.embed = nn.Embedding(self.data_manager.vocab_size, self.embed_size)\n",
    "        self.conv1d_1 = nn.Conv1d(in_channels=self.embed_size, out_channels=self.state_size, kernel_size=3)# Insert your code here\n",
    "        self.conv1d_2 = nn.Conv1d(in_channels=self.embed_size, out_channels=self.state_size, kernel_size=3)# Insert your code here\n",
    "        self.conv1d_3 = nn.Conv1d(in_channels=self.embed_size, out_channels=self.state_size, kernel_size=7)# Insert your code here\n",
    "        self.fc = nn.Linear(state_size*3, self.data_manager.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e = self.embed(x)\n",
    "        #permute x before applying Conv1D\n",
    "        e= e.permute(0,2,1)\n",
    "\n",
    "        #applying Conv1D\n",
    "        h1 = F.relu(self.conv1d_1(e))# Insert your code here\n",
    "        h2 = F.relu(self.conv1d_2(e))# Insert your code here\n",
    "        h3 = F.relu(self.conv1d_3(e))# Insert your code here\n",
    "\n",
    "        #apply GlobalMaxPool\n",
    "        h1 = F.max_pool1d(h1, kernel_size=h1.shape[2]).squeeze(2)# Insert your code here\n",
    "        h2 = F.max_pool1d(h2, kernel_size=h2.shape[2]).squeeze(2)# Insert your code here\n",
    "        h3 = F.max_pool1d(h3, kernel_size=h3.shape[2]).squeeze(2)# Insert your code here\n",
    "\n",
    "        h =  torch.cat([h1, h2, h3], dim=1)# Insert your code here\n",
    "        h = self.fc(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-PN6KmIFw6K"
   },
   "source": [
    "We declare `text_cnn` and train on several epochs (e.g., `50 epochs`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IrL5oM82BR3_",
    "outputId": "be8b3e2e-9993-48ed-fc10-3e5819d0970a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "26/26 - train_loss: 1.4946 - train_accuracy: 41.0369%                 - val_loss: 0.6486 - val_accuracy: 66.1616%\n",
      "Epoch 2/50\n",
      "26/26 - train_loss: 0.9472 - train_accuracy: 79.0756%                 - val_loss: 0.3782 - val_accuracy: 81.8182%\n",
      "Epoch 3/50\n",
      "26/26 - train_loss: 0.5159 - train_accuracy: 87.9450%                 - val_loss: 0.2682 - val_accuracy: 89.3939%\n",
      "Epoch 4/50\n",
      "26/26 - train_loss: 0.2982 - train_accuracy: 95.0031%                 - val_loss: 0.1904 - val_accuracy: 92.9293%\n",
      "Epoch 5/50\n",
      "26/26 - train_loss: 0.1830 - train_accuracy: 97.3766%                 - val_loss: 0.1549 - val_accuracy: 94.9495%\n",
      "Epoch 6/50\n",
      "26/26 - train_loss: 0.1261 - train_accuracy: 99.0631%                 - val_loss: 0.1237 - val_accuracy: 94.4444%\n",
      "Epoch 7/50\n",
      "26/26 - train_loss: 0.0857 - train_accuracy: 99.3129%                 - val_loss: 0.0951 - val_accuracy: 95.9596%\n",
      "Epoch 8/50\n",
      "26/26 - train_loss: 0.0591 - train_accuracy: 99.8751%                 - val_loss: 0.0923 - val_accuracy: 96.4646%\n",
      "Epoch 9/50\n",
      "26/26 - train_loss: 0.0432 - train_accuracy: 100.0000%                 - val_loss: 0.0773 - val_accuracy: 96.4646%\n",
      "Epoch 10/50\n",
      "26/26 - train_loss: 0.0333 - train_accuracy: 100.0000%                 - val_loss: 0.0804 - val_accuracy: 95.9596%\n",
      "Epoch 11/50\n",
      "26/26 - train_loss: 0.0263 - train_accuracy: 100.0000%                 - val_loss: 0.0791 - val_accuracy: 95.9596%\n",
      "Epoch 12/50\n",
      "26/26 - train_loss: 0.0233 - train_accuracy: 100.0000%                 - val_loss: 0.0528 - val_accuracy: 95.9596%\n",
      "Epoch 13/50\n",
      "26/26 - train_loss: 0.0206 - train_accuracy: 100.0000%                 - val_loss: 0.0707 - val_accuracy: 95.4545%\n",
      "Epoch 14/50\n",
      "26/26 - train_loss: 0.0148 - train_accuracy: 100.0000%                 - val_loss: 0.0414 - val_accuracy: 95.9596%\n",
      "Epoch 15/50\n",
      "26/26 - train_loss: 0.0119 - train_accuracy: 100.0000%                 - val_loss: 0.0504 - val_accuracy: 96.4646%\n",
      "Epoch 16/50\n",
      "26/26 - train_loss: 0.0106 - train_accuracy: 100.0000%                 - val_loss: 0.0478 - val_accuracy: 96.4646%\n",
      "Epoch 17/50\n",
      "26/26 - train_loss: 0.0103 - train_accuracy: 100.0000%                 - val_loss: 0.0393 - val_accuracy: 95.9596%\n",
      "Epoch 18/50\n",
      "26/26 - train_loss: 0.0082 - train_accuracy: 100.0000%                 - val_loss: 0.0423 - val_accuracy: 95.9596%\n",
      "Epoch 19/50\n",
      "26/26 - train_loss: 0.0070 - train_accuracy: 100.0000%                 - val_loss: 0.0376 - val_accuracy: 95.4545%\n",
      "Epoch 20/50\n",
      "26/26 - train_loss: 0.0064 - train_accuracy: 100.0000%                 - val_loss: 0.0411 - val_accuracy: 95.9596%\n",
      "Epoch 21/50\n",
      "26/26 - train_loss: 0.0056 - train_accuracy: 100.0000%                 - val_loss: 0.0345 - val_accuracy: 95.4545%\n",
      "Epoch 22/50\n",
      "26/26 - train_loss: 0.0049 - train_accuracy: 100.0000%                 - val_loss: 0.0352 - val_accuracy: 95.9596%\n",
      "Epoch 23/50\n",
      "26/26 - train_loss: 0.0044 - train_accuracy: 100.0000%                 - val_loss: 0.0320 - val_accuracy: 95.4545%\n",
      "Epoch 24/50\n",
      "26/26 - train_loss: 0.0042 - train_accuracy: 100.0000%                 - val_loss: 0.0303 - val_accuracy: 95.4545%\n",
      "Epoch 25/50\n",
      "26/26 - train_loss: 0.0045 - train_accuracy: 100.0000%                 - val_loss: 0.0261 - val_accuracy: 95.9596%\n",
      "Epoch 26/50\n",
      "26/26 - train_loss: 0.0034 - train_accuracy: 100.0000%                 - val_loss: 0.0236 - val_accuracy: 95.9596%\n",
      "Epoch 27/50\n",
      "26/26 - train_loss: 0.0031 - train_accuracy: 100.0000%                 - val_loss: 0.0249 - val_accuracy: 96.9697%\n",
      "Epoch 28/50\n",
      "26/26 - train_loss: 0.0029 - train_accuracy: 100.0000%                 - val_loss: 0.0245 - val_accuracy: 95.9596%\n",
      "Epoch 29/50\n",
      "26/26 - train_loss: 0.0028 - train_accuracy: 100.0000%                 - val_loss: 0.0235 - val_accuracy: 95.9596%\n",
      "Epoch 30/50\n",
      "26/26 - train_loss: 0.0025 - train_accuracy: 100.0000%                 - val_loss: 0.0215 - val_accuracy: 95.9596%\n",
      "Epoch 31/50\n",
      "26/26 - train_loss: 0.0023 - train_accuracy: 100.0000%                 - val_loss: 0.0218 - val_accuracy: 95.9596%\n",
      "Epoch 32/50\n",
      "26/26 - train_loss: 0.0021 - train_accuracy: 100.0000%                 - val_loss: 0.0201 - val_accuracy: 95.9596%\n",
      "Epoch 33/50\n",
      "26/26 - train_loss: 0.0020 - train_accuracy: 100.0000%                 - val_loss: 0.0206 - val_accuracy: 95.9596%\n",
      "Epoch 34/50\n",
      "26/26 - train_loss: 0.0023 - train_accuracy: 100.0000%                 - val_loss: 0.0196 - val_accuracy: 95.9596%\n",
      "Epoch 35/50\n",
      "26/26 - train_loss: 0.0018 - train_accuracy: 100.0000%                 - val_loss: 0.0199 - val_accuracy: 95.9596%\n",
      "Epoch 36/50\n",
      "26/26 - train_loss: 0.0017 - train_accuracy: 100.0000%                 - val_loss: 0.0184 - val_accuracy: 95.9596%\n",
      "Epoch 37/50\n",
      "26/26 - train_loss: 0.0016 - train_accuracy: 100.0000%                 - val_loss: 0.0177 - val_accuracy: 95.9596%\n",
      "Epoch 38/50\n",
      "26/26 - train_loss: 0.0015 - train_accuracy: 100.0000%                 - val_loss: 0.0168 - val_accuracy: 95.9596%\n",
      "Epoch 39/50\n",
      "26/26 - train_loss: 0.0014 - train_accuracy: 100.0000%                 - val_loss: 0.0161 - val_accuracy: 95.9596%\n",
      "Epoch 40/50\n",
      "26/26 - train_loss: 0.0014 - train_accuracy: 100.0000%                 - val_loss: 0.0156 - val_accuracy: 95.9596%\n",
      "Epoch 41/50\n",
      "26/26 - train_loss: 0.0013 - train_accuracy: 100.0000%                 - val_loss: 0.0154 - val_accuracy: 95.9596%\n",
      "Epoch 42/50\n",
      "26/26 - train_loss: 0.0012 - train_accuracy: 100.0000%                 - val_loss: 0.0147 - val_accuracy: 95.9596%\n",
      "Epoch 43/50\n",
      "26/26 - train_loss: 0.0012 - train_accuracy: 100.0000%                 - val_loss: 0.0149 - val_accuracy: 95.9596%\n",
      "Epoch 44/50\n",
      "26/26 - train_loss: 0.0014 - train_accuracy: 100.0000%                 - val_loss: 0.0145 - val_accuracy: 95.9596%\n",
      "Epoch 45/50\n",
      "26/26 - train_loss: 0.0012 - train_accuracy: 100.0000%                 - val_loss: 0.0137 - val_accuracy: 95.9596%\n",
      "Epoch 46/50\n",
      "26/26 - train_loss: 0.0010 - train_accuracy: 100.0000%                 - val_loss: 0.0132 - val_accuracy: 95.9596%\n",
      "Epoch 47/50\n",
      "26/26 - train_loss: 0.0011 - train_accuracy: 100.0000%                 - val_loss: 0.0131 - val_accuracy: 95.9596%\n",
      "Epoch 48/50\n",
      "26/26 - train_loss: 0.0009 - train_accuracy: 100.0000%                 - val_loss: 0.0135 - val_accuracy: 95.9596%\n",
      "Epoch 49/50\n",
      "26/26 - train_loss: 0.0008 - train_accuracy: 100.0000%                 - val_loss: 0.0123 - val_accuracy: 95.9596%\n",
      "Epoch 50/50\n",
      "26/26 - train_loss: 0.0009 - train_accuracy: 100.0000%                 - val_loss: 0.0117 - val_accuracy: 95.9596%\n"
     ]
    }
   ],
   "source": [
    "text_cnn = TextCNN(data_manager=dm).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(text_cnn.parameters(), lr=0.001)\n",
    "trainer = BaseTrainer(model=text_cnn, criterion=criterion, optimizer=optimizer, train_loader=dm.train_loader, val_loader=dm.valid_loader)\n",
    "trainer.fit(num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yrjO5iT6F_Li"
   },
   "source": [
    "We evaluate the trained model on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CnHiWCl7BtJC",
    "outputId": "6c6417eb-65a0-45c0-b6f7-71237c0b471e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.1813 - test_accuracy: 93.5323%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = trainer.evaluate(dm.test_loader)\n",
    "print(f'test_loss: {test_loss:.4f} - test_accuracy: {test_acc*100:.4f}%')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:mamba-codegeex-agent]",
   "language": "python",
   "name": "conda-env-mamba-codegeex-agent-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "088877c46d6b4b24a8174c06af291d80": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "092596ba1aff4156abaf7c4551ef4b90": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_088877c46d6b4b24a8174c06af291d80",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4c8dd3ea42994f449a4cbdcefbdf3667",
      "value": 570
     }
    },
    "1959329e8d6943389b2afb3de07991bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f691af8ecb14909a2156bb27ee6ad48",
      "placeholder": "",
      "style": "IPY_MODEL_d6f3f6ce1b0041b9830a487909629025",
      "value": "config.json:100%"
     }
    },
    "1fae6119720c4674ba6bb515fed454d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33a8ee2c2fc241e6be761c0adbb6f812": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3586e1b95c204a8f9ce03c69d03452aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f691af8ecb14909a2156bb27ee6ad48": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43850453eb604bd7a5433c4c69c951a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d5a5bec95544fb6be49b6df7bec2f08",
      "placeholder": "",
      "style": "IPY_MODEL_b047c36d76a74476a6ea8955ec16e74d",
      "value": "466k/466k[00:00&lt;00:00,3.60MB/s]"
     }
    },
    "45d9d7f9ac224478b56701c7a3f507a0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c8dd3ea42994f449a4cbdcefbdf3667": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "50cee50f3442475c80feced314145282": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ce9e9eebd38544f5b25b98a0e2cdf34c",
       "IPY_MODEL_af621002a3084382970b6b411c765efd",
       "IPY_MODEL_fe1d0c8f685243dfbc6e243fa5671239"
      ],
      "layout": "IPY_MODEL_87ddbec7ee2b475aa6433b0af006e690"
     }
    },
    "53ab4df9ff3d40289a61fefed1be62b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1959329e8d6943389b2afb3de07991bd",
       "IPY_MODEL_092596ba1aff4156abaf7c4551ef4b90",
       "IPY_MODEL_9d6eef5c1fb64392b12dba68370671e6"
      ],
      "layout": "IPY_MODEL_e9c7a604175f4d899b5deefb5adb0aac"
     }
    },
    "542e549dd3bc4b6a839ded3923a99904": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54eae932f71d433197317c8b601bb10f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b5c118d653d482fbc529152e891bed9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5b8b88361e2a4d1897574cd59c6b0d76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "639688ae9f8c4009ac1c2c89e531686f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6a60ae03c3784a7da5648c5169383ab2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d5a5bec95544fb6be49b6df7bec2f08": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6dbb51e48bf04353955a4183f59294fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6a60ae03c3784a7da5648c5169383ab2",
      "placeholder": "",
      "style": "IPY_MODEL_54eae932f71d433197317c8b601bb10f",
      "value": "tokenizer.json:100%"
     }
    },
    "721f087bb68e4adeb1a9a0732b83d735": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "73188d0e6e2d485d9326233d8e1e65b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f40e6d522a4473383e66111101348ed",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7ca8e7cb308d4784a96b7f06ca0ba1aa",
      "value": 466062
     }
    },
    "7b2401a4710044b29da4222ca8a61da9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ca8e7cb308d4784a96b7f06ca0ba1aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "87ddbec7ee2b475aa6433b0af006e690": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8e48e0022ad94e79ae79d3efaa1c10bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8f40e6d522a4473383e66111101348ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d6eef5c1fb64392b12dba68370671e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_542e549dd3bc4b6a839ded3923a99904",
      "placeholder": "",
      "style": "IPY_MODEL_639688ae9f8c4009ac1c2c89e531686f",
      "value": "570/570[00:00&lt;00:00,3.49kB/s]"
     }
    },
    "a756e535702c4f0285f9821eece1dd68": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af621002a3084382970b6b411c765efd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a756e535702c4f0285f9821eece1dd68",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ce1a58065c734481990ed9214270319a",
      "value": 48
     }
    },
    "b047c36d76a74476a6ea8955ec16e74d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b330fcb1039542c5a9c05b1c99b882a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bdb7b835bbfe47d8910cd1c0e37c8fb7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6dbb51e48bf04353955a4183f59294fb",
       "IPY_MODEL_73188d0e6e2d485d9326233d8e1e65b2",
       "IPY_MODEL_43850453eb604bd7a5433c4c69c951a4"
      ],
      "layout": "IPY_MODEL_1fae6119720c4674ba6bb515fed454d3"
     }
    },
    "c246219a569b4b949f35d797b6d9c3f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd58168653b84dbcaadcd8be386b07d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cfb730e25de348da9ea60e3b60efaf52",
       "IPY_MODEL_cd90f84da1034182b5bc09619d36425e",
       "IPY_MODEL_cd5bd48749f947d1bf5a4e8c9f95c993"
      ],
      "layout": "IPY_MODEL_33a8ee2c2fc241e6be761c0adbb6f812"
     }
    },
    "cd5bd48749f947d1bf5a4e8c9f95c993": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d577812b012440949879a174567faa9d",
      "placeholder": "",
      "style": "IPY_MODEL_c246219a569b4b949f35d797b6d9c3f0",
      "value": "232k/232k[00:00&lt;00:00,1.83MB/s]"
     }
    },
    "cd90f84da1034182b5bc09619d36425e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b330fcb1039542c5a9c05b1c99b882a2",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8e48e0022ad94e79ae79d3efaa1c10bd",
      "value": 231508
     }
    },
    "ce1a58065c734481990ed9214270319a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ce9e9eebd38544f5b25b98a0e2cdf34c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3586e1b95c204a8f9ce03c69d03452aa",
      "placeholder": "",
      "style": "IPY_MODEL_721f087bb68e4adeb1a9a0732b83d735",
      "value": "tokenizer_config.json:100%"
     }
    },
    "cfb730e25de348da9ea60e3b60efaf52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7b2401a4710044b29da4222ca8a61da9",
      "placeholder": "",
      "style": "IPY_MODEL_5b8b88361e2a4d1897574cd59c6b0d76",
      "value": "vocab.txt:100%"
     }
    },
    "d577812b012440949879a174567faa9d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6f3f6ce1b0041b9830a487909629025": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e9c7a604175f4d899b5deefb5adb0aac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe1d0c8f685243dfbc6e243fa5671239": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45d9d7f9ac224478b56701c7a3f507a0",
      "placeholder": "",
      "style": "IPY_MODEL_5b5c118d653d482fbc529152e891bed9",
      "value": "48.0/48.0[00:00&lt;00:00,1.85kB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
